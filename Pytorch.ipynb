{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Function\n",
    "from torchsummary import summary\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ReverseLayer(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output = grad_output.neg() * ctx.alpha\n",
    "\n",
    "        return output, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder():\n",
    "    model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet34')\n",
    "    modules = list(model.children())[:-1] + [torch.nn.Flatten()]\n",
    "    model = nn.Sequential(*modules)\n",
    "    return model\n",
    "\n",
    "def build_classifier(input_shape, classes, joint=True):\n",
    "    domains = 2 if joint else 1\n",
    "    \n",
    "    classifier = nn.Sequential(\n",
    "        nn.Linear(input_shape, 1280),\n",
    "        nn.ReLU(True),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(1280, 1280),\n",
    "        nn.ReLU(True),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(1280, domains*classes),\n",
    "        nn.Softmax()\n",
    "    )\n",
    "    return classifier\n",
    "\n",
    "def build_discriminator(input_shape):\n",
    "    discriminator = nn.Sequential(\n",
    "        nn.Linear(input_shape, 1280),\n",
    "        nn.ReLU(True),\n",
    "        nn.Linear(1280, 1280),\n",
    "        nn.ReLU(True),\n",
    "        nn.Linear(1280, 2),\n",
    "        nn.Softmax()\n",
    "    )\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, labels=True):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        return x if self.labels else x[0]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(\n",
    "        self, \n",
    "        source_domain,\n",
    "        target_domain,\n",
    "        val_split=0.2,\n",
    "        test_split=0.2,\n",
    "        input_shape=(224,224),\n",
    "        target_labels=0.1,\n",
    "        target_train=False\n",
    "    ):\n",
    "        src_train, src_val = self.__prepare_data(\n",
    "            source_domain, \n",
    "            input_shape,\n",
    "            True, \n",
    "            val_split,\n",
    "            test_split,\n",
    "            target_labels\n",
    "        )\n",
    "              \n",
    "        train_label, train_nlabel, tar_val, test = self.__prepare_data(\n",
    "            target_domain,  \n",
    "            input_shape, \n",
    "            False, \n",
    "            val_split,\n",
    "            test_split,\n",
    "            target_labels\n",
    "        )\n",
    "        \n",
    "        if len(tar_val) <= 10:\n",
    "            val = torch.utils.data.ConcatDataset([src_val, tar_val])\n",
    "        else:\n",
    "            val = tar_val\n",
    "        \n",
    "#         if target_train:\n",
    "#             train_label_set = train_label\n",
    "#         else:\n",
    "#             train_label_set = torch.utils.data.ConcatDataset([src_train, train_label])\n",
    "\n",
    "        self.train_src_loader = DataLoader(dataset=src_train, batch_size=32, shuffle=True, num_workers=0)\n",
    "        self.train_tar_label_loader = DataLoader(dataset=train_label, batch_size=32, shuffle=True, num_workers=0)\n",
    "        \n",
    "        if target_labels < 1:\n",
    "            self.train_tar_nlabel_loader = DataLoader(dataset=train_nlabel, batch_size=32, shuffle=True, num_workers=0)\n",
    "        else:\n",
    "            self.train_tar_nlabel_loader = None\n",
    "            \n",
    "        self.val_loader = DataLoader(dataset=val, batch_size=64, shuffle=True, num_workers=0)\n",
    "        self.test_loader = DataLoader(dataset=test, batch_size=64, shuffle=True, num_workers=0)\n",
    "    \n",
    "    def __prepare_data(self, folder, input_shape, src=True, val_split=0, test_split=0, target_labels=0.1):\n",
    "        \n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(input_shape),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        \n",
    "        label = 0 if src else 1\n",
    "        \n",
    "        data = torchvision.datasets.ImageFolder(folder, transform=transform)\n",
    "        data.target_transform = lambda id: torch.Tensor((label, id))\n",
    "        \n",
    "        self.classes = data.classes\n",
    "        \n",
    "        if src:\n",
    "            \n",
    "            train, val = torch.utils.data.random_split(\n",
    "                data, \n",
    "                [round(len(data)*(1-val_split) - 1e-5), round(len(data)*val_split + 1e-5)]\n",
    "            ) \n",
    "            \n",
    "            return train, val\n",
    "        \n",
    "        else:\n",
    "            data, test = torch.utils.data.random_split(\n",
    "                data, \n",
    "                [round(len(data)*(1-test_split) - 1e-5), round(len(data)*test_split + 1e-5)]\n",
    "            )\n",
    "        \n",
    "            train, train_nlabel = torch.utils.data.random_split(\n",
    "                data, \n",
    "                [round(len(data)*target_labels - 1e-5), round(len(data)*(1-target_labels) + 1e-5)]\n",
    "            ) \n",
    "    \n",
    "            train_label, val = torch.utils.data.random_split(\n",
    "                train, \n",
    "                [round(len(train)*(1-val_split) - 1e-5), round(len(train)*val_split + 1e-5)]\n",
    "            )\n",
    "            \n",
    "            return train_label, Dataset(train_nlabel, False), val, test\n",
    "        \n",
    "    def train_data(self):\n",
    "        return train_src_loader, self.train_tar_label_loader, self.train_tar_nlabel_loader\n",
    "    \n",
    "    def val_data(self):\n",
    "        return self.val_loader\n",
    "    \n",
    "    def test_data(self):\n",
    "        return self.test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../Datasets/Experiment\"\n",
    "src_folder = os.path.join(data_folder, \"Real World\")\n",
    "target_folder = os.path.join(data_folder, \"Product\")\n",
    "\n",
    "d = DataGenerator(\n",
    "    source_domain=src_folder,\n",
    "    target_domain=target_folder,\n",
    "    val_split=0.2,\n",
    "    test_split=0.2,\n",
    "    input_shape=(224,224),\n",
    "    target_labels=0.01,\n",
    "    target_train=False\n",
    ")\n",
    "\n",
    "train_label, train_nlabel = d.train_data()\n",
    "val = d.val_data()\n",
    "test = d.test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_Loss(y_pred, classes):\n",
    "    y_joint = torch.reshape(y_pred, (-1, 2*classes))\n",
    "    \n",
    "    y_class = torch.unsqueeze(torch.sum(y_pred, 1), 1)\n",
    "    y_domain = torch.unsqueeze(torch.sum(y_pred, 2), -1)\n",
    "    \n",
    "    \n",
    "    y_ind_joint = torch.reshape((y_domain * y_class), (-1,2*classes))\n",
    "    \n",
    "    return torch.nn.KLDivLoss(log_target=True, reduction=\"sum\")(\n",
    "        torch.log(y_joint), \n",
    "        torch.log(y_ind_joint)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DANNModel(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        classes=65,\n",
    "    ):\n",
    "        super(SingleDomainModel, self).__init__()\n",
    "        self.classes = classes\n",
    "        self.encoder = build_encoder()\n",
    "        self.classifier = build_classifier(512, self.classes)\n",
    "        self.discriminator = build_discriminator(512)\n",
    "    \n",
    "    def forward(self, inputs, rep_loss):\n",
    "        features = self.encoder(inputs)\n",
    "        classes = self.classifier(features)\n",
    "        classes = torch.reshape(classes, (-1, 2, self.classes))\n",
    "        domains = self.discriminator(ReverseLayer.apply(features, rep_loss))\n",
    "        return classes, domains\n",
    "    \n",
    "    def run_batch(self, imgs, labels=None, training=True, use_KL=True, rep_loss=1, risk_loss=1):\n",
    "        if training:\n",
    "            opt = optim.Adam(self.parameters(), lr=1e-4)\n",
    "#             opt = torch.optim.SGD(m.parameters(), lr=1e-4, momentum=0.9, weight_decay=5e-4)\n",
    "            opt.zero_grad()\n",
    "            \n",
    "        kl_loss = 0\n",
    "        class_pred_loss = 0\n",
    "        pred_count_joint = 0\n",
    "        pred_count_class = 0\n",
    "        \n",
    "        imgs = imgs.cuda()\n",
    "        y_pred, domain_pred_label = self(imgs, rep_loss) \n",
    "        \n",
    "        if labels is not None:\n",
    "            labels = labels.cuda()\n",
    "            labels = labels.to(dtype=torch.int64)\n",
    "            joint_labels = labels[:,0] * m.classes + labels[:,1]\n",
    "            dom_labels = torch.cat((labels[:,0], torch.ones(imgs.shape[0] - labels.shape[0], dtype=torch.long).cuda()), 0)\n",
    "\n",
    "            y_pred = y_pred[:labels.shape[0]]\n",
    "            y_joint = torch.reshape(y_pred, (-1,2*m.classes))\n",
    "            y_class = torch.sum(y_pred, 1)\n",
    "\n",
    "            if use_KL:\n",
    "                kl_loss = KL_Loss(y_pred, m.classes) * risk_loss\n",
    "\n",
    "            class_pred_loss = torch.nn.NLLLoss()(torch.log(y_class), labels[:,1])\n",
    "            \n",
    "            pred_count_joint = torch.count_nonzero(torch.argmax(y_joint, 1) == joint_labels)\n",
    "            pred_count_class = torch.count_nonzero(torch.argmax(y_class, 1) == labels[:,1])\n",
    "             \n",
    "        dis_loss = torch.nn.NLLLoss()(torch.log(domain_pred_label), dom_labels)\n",
    "        dis_count = torch.count_nonzero(torch.argmax(domain_pred_label, 1) == dom_labels)\n",
    "        \n",
    "        loss = class_pred_loss + kl_loss + dis_loss\n",
    "\n",
    "        if training:\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        return (\n",
    "            float(loss), \n",
    "            float(kl_loss), \n",
    "            float(class_pred_loss), \n",
    "            float(dis_loss), \n",
    "            float(pred_count_joint), \n",
    "            float(pred_count_class),\n",
    "            float(dis_count)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DANNModel(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        classes=65,\n",
    "        use_KL=True,\n",
    "        risk_lambda=1,\n",
    "        rep_lambda=1\n",
    "        lr=1e-4\n",
    "    ):\n",
    "        super(DANNModel, self).__init__()\n",
    "        self.classes = classes\n",
    "        self.encoder = build_encoder()\n",
    "        self.classifier = build_classifier(512, self.classes, use_KL)\n",
    "        self.discriminator = build_discriminator(512)\n",
    "        \n",
    "        self.lr = lr\n",
    "        \n",
    "        self.use_KL = use_KL\n",
    "        self.risk_lambda = risk_lambda\n",
    "        self.rep_lambda = rep_lambda\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        features = self.encoder(inputs)\n",
    "        classes = self.classifier(features)\n",
    "        if self.use_KL:\n",
    "            classes = torch.reshape(classes, (-1, 2, self.classes))\n",
    "        domains = self.discriminator(ReverseLayer.apply(features, rep_loss))\n",
    "        return classes, domains\n",
    "    \n",
    "    def __print_metrics(self, metrics, prefix=\"\", precision=4, space=1):\n",
    "        for k, v in metrics.items():\n",
    "            print(prefix + k, round(v, precision), sep=\": \", end=' ')\n",
    "        for i in range(space):\n",
    "            print()\n",
    "    \n",
    "    def __train_encoder_discriminator(self, imgs, y_labels, domain_labels):\n",
    "        opt = optim.Adam(self.encoder.parameters() + self.discriminator.parameters(), lr=self.lr)\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        # Feedforward\n",
    "        y_pred, domain_pred = self(imgs) \n",
    "        y_class = torch.sum(y_pred, 1)\n",
    "        \n",
    "        # Calculate losses and metrics\n",
    "        class_pred_loss = torch.nn.NLLLoss()(torch.log(y_class), y_labels)\n",
    "        kl_loss = KL_Loss(y_pred, m.classes) * self.risk_lambda\n",
    "        dis_loss = torch.nn.NLLLoss()(torch.log(domain_pred), domain_labels) * self.rep_lambda\n",
    "        \n",
    "        loss = class_pred_loss + kl_loss + dis_loss\n",
    "        \n",
    "        # Backpropogation\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        return y_class, float(loss), float(kl_loss), float(dis_loss)\n",
    "            \n",
    "    def __train_classifier(self, imgs, labels):\n",
    "        classifier_opt = optim.Adam(self.encoder.parameters(), lr=self.lr)\n",
    "        classifier_opt.zero_grad()\n",
    "        \n",
    "        # Feedforward\n",
    "        y_pred, _ = self(imgs) \n",
    "        y_joint = torch.reshape(y_pred, (-1,2*m.classes))          \n",
    "\n",
    "        # Calculate losses and metrics\n",
    "        joint_pred_loss = torch.nn.NLLLoss()(torch.log(y_joint), labels)\n",
    "        classifier_loss = joint_pred_loss\n",
    "        \n",
    "        # Backpropogation\n",
    "        classifier_loss.backward()\n",
    "        classifier_opt.step()\n",
    "        \n",
    "        return y_pred, float(classifier_loss)\n",
    "    \n",
    "    def __full_training(self, imgs, y_labels, domain_labels):\n",
    "        opt = optim.Adam(self.parameters(), lr=self.lr)\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        # Feedforward\n",
    "        y_pred, domain_pred = self(imgs) \n",
    "        \n",
    "        # Calculate losses and metrics\n",
    "        class_pred_loss = torch.nn.NLLLoss()(torch.log(y_pred), labels)\n",
    "        dis_loss = torch.nn.NLLLoss()(torch.log(domain_pred), domain_labels) * self.rep_lambda\n",
    "        loss = class_pred_loss + dis_loss\n",
    "        \n",
    "        # Backpropogation\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        return y_pred, float(loss), float(dis_loss)\n",
    "    \n",
    "    def __train_batch(self, imgs, labels=None):\n",
    "        \n",
    "        imgs = imgs.cuda()\n",
    "        \n",
    "        if labels is not None:\n",
    "            labels = labels.cuda()\n",
    "            labels = labels.to(dtype=torch.int64)\n",
    "            class_labels = labels[:,1]\n",
    "            joint_labels = labels[:,0] * m.classes + labels[:,1]\n",
    "            domain_labels = torch.cat((labels[:,0], torch.ones(imgs.shape[0] - labels.shape[0], dtype=torch.long).cuda()), 0)\n",
    "        \n",
    "        if self.use_KL:\n",
    "            # Two step training of encoder/discriminator and classifier with KL-loss\n",
    "            _, encoder_loss, kl_loss, dis_loss = self.__train_encoder_discriminator(imgs, class_labels, domain_labels)\n",
    "            y_pred, classifier_loss = self.__train_classifier(imgs, joint_labels)\n",
    "            \n",
    "            y_class = torch.sum(y_pred, 1)\n",
    "            y_joint = torch.reshape(y_pred, (-1,2*m.classes))\n",
    "            \n",
    "            pred_class_count = torch.count_nonzero(torch.argmax(y_class, 1) == class_labels)\n",
    "            pred_joint_count = torch.count_nonzero(torch.argmax(y_joint, 1) == joint_labels)\n",
    "            pred_dis_count = torch.count_nonzero(torch.argmax(y_joint, 1) == joint_labels)\n",
    "            \n",
    "            loss_metrics = {\n",
    "                \"loss\": encoder_loss + classifier_loss,\n",
    "                \"encoder_loss\": encoder_loss,\n",
    "                \"kl_loss\": kl_loss,\n",
    "                \"disciminator_loss\": dis_loss,\n",
    "                \"classifier_loss\": classifier_loss\n",
    "            }\n",
    "            \n",
    "            acc_metrics = {\n",
    "                \"joint_acc\": float(pred_joint_count),\n",
    "                \"class_acc\": float(pred_class_count)\n",
    "            }\n",
    "            \n",
    "        else:\n",
    "            y_pred, loss = self.__full_training(imgs, class_labels)\n",
    "            \n",
    "            pred_class_count = torch.count_nonzero(torch.argmax(y_pred, 1) == class_labels)\n",
    "            \n",
    "            loss_metrics = {\n",
    "                \"loss\": loss\n",
    "            }\n",
    "            \n",
    "            acc_metrics = {\n",
    "                \"class_acc\": float(pred_class_count)\n",
    "            }\n",
    "\n",
    "        return loss_metrics, acc_metrics\n",
    "    \n",
    "    def train(self, epochs, train_loader, val_loader=None, patience=None, verbose=True):\n",
    "        \n",
    "        train_size = len(train_loader.dataset)\n",
    "        min_val_loss = np.inf\n",
    "        best_model = None\n",
    "        \n",
    "        current_patience = patience\n",
    "        \n",
    "        # Perform training over number of epochs\n",
    "        for i in range(epochs):\n",
    "            if verbose:\n",
    "                print(f\"Epoch {i+1}\")\n",
    "            \n",
    "            loss_metrics = defaultdict(float)\n",
    "            acc_metrics = defaultdict(float)\n",
    "            \n",
    "            for imgs, labels in train_loader:\n",
    "                batch_loss, batch_acc = self.__train_batch(imgs, labels)\n",
    "\n",
    "                for k, v in batch_loss.items():\n",
    "                    loss_metrics[k] += v / train_size\n",
    "                for k, v in batch_acc.items():\n",
    "                    acc_metrics[k] += v / train_size\n",
    "                    \n",
    "            if verbose:\n",
    "                self.__print_metrics(loss_metrics, precision=6)\n",
    "                self.__print_metrics(acc_metrics, precision=4, space=2)\n",
    "            \n",
    "            # Run on validation set if provided\n",
    "            if val_loader is not None:\n",
    "                val_size = len(val_loader.dataset)\n",
    "                loss_metrics, acc_metrics = self.evaluate(val_loader, val=True, verbose=verbose)\n",
    "                \n",
    "                # Early stopping\n",
    "                if loss_metrics[\"loss\"] < min_val_loss:\n",
    "                    min_val_loss = loss_metrics[\"loss\"]\n",
    "                    best_model = copy.deepcopy(self.state_dict())\n",
    "                    current_patience = patience\n",
    "                else:\n",
    "                    if current_patience is not None:\n",
    "                        current_patience -= 1\n",
    "                        if current_patience <= 0:\n",
    "                            break\n",
    "                        \n",
    "        self.load_state_dict(best_model)\n",
    "    \n",
    "    def evaluate(self, loader, val=False, verbose=True):\n",
    "        \n",
    "        data_size = len(loader.dataset)\n",
    "        loss_metrics = defaultdict(float)\n",
    "        acc_metrics = defaultdict(float)\n",
    "        \n",
    "        for imgs, labels in loader:\n",
    "            batch_loss, batch_acc = self.__evaluate_batch(imgs, labels)\n",
    "            \n",
    "            for k, v in batch_loss.items():\n",
    "                loss_metrics[k] += v / data_size\n",
    "            for k, v in batch_acc.items():\n",
    "                acc_metrics[k] += v / data_size\n",
    "                \n",
    "        prefix = \"val_\" if val else \"\"\n",
    "        \n",
    "        if verbose:\n",
    "            self.__print_metrics(loss_metrics, prefix=prefix, precision=6)\n",
    "            self.__print_metrics(acc_metrics, prefix=prefix, precision=4, space=2)\n",
    "                \n",
    "        return loss_metrics, acc_metrics\n",
    "            \n",
    "    def __evaluate_batch(self, imgs, labels):\n",
    "        imgs = imgs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        labels = labels.to(dtype=torch.int64)\n",
    "        class_labels = labels[:,1]\n",
    "        joint_labels = labels[:,0] * m.classes + labels[:,1]\n",
    "        \n",
    "        # Feedforward\n",
    "        y_pred = self(imgs)\n",
    "        \n",
    "        if self.use_KL:           \n",
    "            y_class = torch.sum(y_pred, 1)\n",
    "            y_joint = torch.reshape(y_pred, (-1,2*m.classes))\n",
    "            \n",
    "            class_pred_loss = float(torch.nn.NLLLoss()(torch.log(y_class), class_labels))\n",
    "            joint_pred_loss = float(torch.nn.NLLLoss()(torch.log(y_joint), joint_labels))\n",
    "            kl_loss = float(KL_Loss(y_pred, m.classes) * self.risk_lambda)\n",
    "            \n",
    "            encoder_loss = class_pred_loss + kl_loss\n",
    "            \n",
    "            pred_class_count = torch.count_nonzero(torch.argmax(y_class, 1) == class_labels)\n",
    "            \n",
    "            loss_metrics = {\n",
    "                \"loss\": encoder_loss,\n",
    "                \"kl_loss\": kl_loss,\n",
    "                \"classifier_loss\": class_pred_loss\n",
    "            }\n",
    "            \n",
    "            acc_metrics = {\n",
    "                \"class_acc\": float(pred_class_count)\n",
    "            }\n",
    "            \n",
    "        else:          \n",
    "            pred_class_count = torch.count_nonzero(torch.argmax(y_pred, 1) == class_labels)\n",
    "            loss = float(torch.nn.NLLLoss()(torch.log(y_pred), class_labels))\n",
    "            \n",
    "            loss_metrics = {\n",
    "                \"loss\": loss\n",
    "            }\n",
    "            \n",
    "            acc_metrics = {\n",
    "                \"class_acc\": float(pred_class_count)\n",
    "            }\n",
    "\n",
    "        return loss_metrics, acc_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleDomainModel(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        classes=65,\n",
    "        use_KL=True,\n",
    "        risk_lambda=1,\n",
    "        lr=1e-4\n",
    "    ):\n",
    "        super(SingleDomainModel, self).__init__()\n",
    "        self.classes = classes\n",
    "        self.encoder = build_encoder()\n",
    "        self.classifier = build_classifier(512, self.classes, use_KL)\n",
    "        \n",
    "        self.lr = lr\n",
    "        \n",
    "        self.use_KL = use_KL\n",
    "        self.risk_lambda = risk_lambda\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        features = self.encoder(inputs)\n",
    "        classes = self.classifier(features)\n",
    "        if self.use_KL:\n",
    "            classes = torch.reshape(classes, (-1, 2, self.classes))\n",
    "        return classes\n",
    "    \n",
    "    def __print_metrics(self, metrics, prefix=\"\", precision=4, space=1):\n",
    "        for k, v in metrics.items():\n",
    "            print(prefix + k, round(v, precision), sep=\": \", end=' ')\n",
    "        for i in range(space):\n",
    "            print()\n",
    "    \n",
    "    def __train_encoder(self, imgs, labels):\n",
    "        encoder_opt = optim.Adam(self.encoder.parameters(), lr=self.lr)\n",
    "        encoder_opt.zero_grad()\n",
    "        \n",
    "        # Feedforward\n",
    "        y_pred = self(imgs) \n",
    "        y_class = torch.sum(y_pred, 1)\n",
    "        \n",
    "        # Calculate losses and metrics\n",
    "        class_pred_loss = torch.nn.NLLLoss()(torch.log(y_class), labels)\n",
    "        kl_loss = KL_Loss(y_pred, m.classes) * self.risk_lambda\n",
    "        encoder_loss = class_pred_loss + kl_loss\n",
    "        \n",
    "        # Backpropogation\n",
    "        encoder_loss.backward()\n",
    "        encoder_opt.step()\n",
    "        \n",
    "        return y_class, float(encoder_loss), float(kl_loss)\n",
    "            \n",
    "    def __train_classifier(self, imgs, labels):\n",
    "        classifier_opt = optim.Adam(self.encoder.parameters(), lr=self.lr)\n",
    "        classifier_opt.zero_grad()\n",
    "        \n",
    "        # Feedforward\n",
    "        y_pred = self(imgs) \n",
    "        y_joint = torch.reshape(y_pred, (-1,2*m.classes))          \n",
    "\n",
    "        # Calculate losses and metrics\n",
    "        joint_pred_loss = torch.nn.NLLLoss()(torch.log(y_joint), labels)\n",
    "        classifier_loss = joint_pred_loss\n",
    "        \n",
    "        # Backpropogation\n",
    "        classifier_loss.backward()\n",
    "        classifier_opt.step()\n",
    "        \n",
    "        return y_pred, float(classifier_loss)\n",
    "    \n",
    "    def __full_training(self, imgs, labels):\n",
    "        opt = optim.Adam(self.parameters(), lr=self.lr)\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        # Feedforward\n",
    "        y_pred = self(imgs) \n",
    "        \n",
    "        # Calculate losses and metrics\n",
    "        class_pred_loss = torch.nn.NLLLoss()(torch.log(y_pred), labels)\n",
    "        loss = class_pred_loss\n",
    "        \n",
    "        # Backpropogation\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        return y_pred, float(loss)\n",
    "    \n",
    "    def __train_batch(self, imgs, labels):\n",
    "        \n",
    "        imgs = imgs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        labels = labels.to(dtype=torch.int64)\n",
    "        class_labels = labels[:,1]\n",
    "        joint_labels = labels[:,0] * m.classes + labels[:,1]\n",
    "        \n",
    "        if self.use_KL:\n",
    "            # Two step training of encoder and classifier with KL-loss\n",
    "            _, encoder_loss, kl_loss = self.__train_encoder(imgs, class_labels)\n",
    "            y_pred, classifier_loss = self.__train_classifier(imgs, joint_labels)\n",
    "            \n",
    "            y_class = torch.sum(y_pred, 1)\n",
    "            y_joint = torch.reshape(y_pred, (-1,2*m.classes))\n",
    "            \n",
    "            pred_class_count = torch.count_nonzero(torch.argmax(y_class, 1) == class_labels)\n",
    "            pred_joint_count = torch.count_nonzero(torch.argmax(y_joint, 1) == joint_labels)\n",
    "            \n",
    "            loss_metrics = {\n",
    "                \"loss\": encoder_loss + classifier_loss,\n",
    "                \"encoder_loss\": encoder_loss,\n",
    "                \"kl_loss\": kl_loss,\n",
    "                \"classifier_loss\": classifier_loss\n",
    "            }\n",
    "            \n",
    "            acc_metrics = {\n",
    "                \"joint_acc\": float(pred_joint_count),\n",
    "                \"class_acc\": float(pred_class_count)\n",
    "            }\n",
    "            \n",
    "        else:\n",
    "            y_pred, loss = self.__full_training(imgs, class_labels)\n",
    "            \n",
    "            pred_class_count = torch.count_nonzero(torch.argmax(y_pred, 1) == class_labels)\n",
    "            \n",
    "            loss_metrics = {\n",
    "                \"loss\": loss\n",
    "            }\n",
    "            \n",
    "            acc_metrics = {\n",
    "                \"class_acc\": float(pred_class_count)\n",
    "            }\n",
    "\n",
    "        return loss_metrics, acc_metrics\n",
    "    \n",
    "    def train(self, epochs, train_loader, val_loader=None, patience=None, verbose=True):\n",
    "        \n",
    "        train_size = len(train_loader.dataset)\n",
    "        min_val_loss = np.inf\n",
    "        best_model = None\n",
    "        \n",
    "        current_patience = patience\n",
    "        \n",
    "        # Perform training over number of epochs\n",
    "        for i in range(epochs):\n",
    "            if verbose:\n",
    "                print(f\"Epoch {i+1}\")\n",
    "            \n",
    "            loss_metrics = defaultdict(float)\n",
    "            acc_metrics = defaultdict(float)\n",
    "            \n",
    "            for imgs, labels in train_loader:\n",
    "                batch_loss, batch_acc = self.__train_batch(imgs, labels)\n",
    "\n",
    "                for k, v in batch_loss.items():\n",
    "                    loss_metrics[k] += v / train_size\n",
    "                for k, v in batch_acc.items():\n",
    "                    acc_metrics[k] += v / train_size\n",
    "                    \n",
    "            if verbose:\n",
    "                self.__print_metrics(loss_metrics, precision=6)\n",
    "                self.__print_metrics(acc_metrics, precision=4, space=2)\n",
    "            \n",
    "            # Run on validation set if provided\n",
    "            if val_loader is not None:\n",
    "                val_size = len(val_loader.dataset)\n",
    "                loss_metrics, acc_metrics = self.evaluate(val_loader, val=True, verbose=verbose)\n",
    "                \n",
    "                # Early stopping\n",
    "                if loss_metrics[\"loss\"] < min_val_loss:\n",
    "                    min_val_loss = loss_metrics[\"loss\"]\n",
    "                    best_model = copy.deepcopy(self.state_dict())\n",
    "                    current_patience = patience\n",
    "                else:\n",
    "                    if current_patience is not None:\n",
    "                        current_patience -= 1\n",
    "                        if current_patience <= 0:\n",
    "                            break\n",
    "                        \n",
    "        self.load_state_dict(best_model)\n",
    "    \n",
    "    def evaluate(self, loader, val=False, verbose=True):\n",
    "        \n",
    "        data_size = len(loader.dataset)\n",
    "        loss_metrics = defaultdict(float)\n",
    "        acc_metrics = defaultdict(float)\n",
    "        \n",
    "        for imgs, labels in loader:\n",
    "            batch_loss, batch_acc = self.__evaluate_batch(imgs, labels)\n",
    "            \n",
    "            for k, v in batch_loss.items():\n",
    "                loss_metrics[k] += v / data_size\n",
    "            for k, v in batch_acc.items():\n",
    "                acc_metrics[k] += v / data_size\n",
    "                \n",
    "        prefix = \"val_\" if val else \"\"\n",
    "        \n",
    "        if verbose:\n",
    "            self.__print_metrics(loss_metrics, prefix=prefix, precision=6)\n",
    "            self.__print_metrics(acc_metrics, prefix=prefix, precision=4, space=2)\n",
    "                \n",
    "        return loss_metrics, acc_metrics\n",
    "            \n",
    "    def __evaluate_batch(self, imgs, labels):\n",
    "        imgs = imgs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        labels = labels.to(dtype=torch.int64)\n",
    "        class_labels = labels[:,1]\n",
    "        joint_labels = labels[:,0] * m.classes + labels[:,1]\n",
    "        \n",
    "        # Feedforward\n",
    "        y_pred = self(imgs)\n",
    "        \n",
    "        if self.use_KL:           \n",
    "            y_class = torch.sum(y_pred, 1)\n",
    "            y_joint = torch.reshape(y_pred, (-1,2*m.classes))\n",
    "            \n",
    "            class_pred_loss = float(torch.nn.NLLLoss()(torch.log(y_class), class_labels))\n",
    "            joint_pred_loss = float(torch.nn.NLLLoss()(torch.log(y_joint), joint_labels))\n",
    "            kl_loss = float(KL_Loss(y_pred, m.classes) * self.risk_lambda)\n",
    "            \n",
    "            encoder_loss = class_pred_loss + kl_loss\n",
    "            \n",
    "            pred_class_count = torch.count_nonzero(torch.argmax(y_class, 1) == class_labels)\n",
    "            \n",
    "            loss_metrics = {\n",
    "                \"loss\": encoder_loss,\n",
    "                \"kl_loss\": kl_loss,\n",
    "                \"classifier_loss\": class_pred_loss\n",
    "            }\n",
    "            \n",
    "            acc_metrics = {\n",
    "                \"class_acc\": float(pred_class_count)\n",
    "            }\n",
    "            \n",
    "        else:          \n",
    "            pred_class_count = torch.count_nonzero(torch.argmax(y_pred, 1) == class_labels)\n",
    "            loss = float(torch.nn.NLLLoss()(torch.log(y_pred), class_labels))\n",
    "            \n",
    "            loss_metrics = {\n",
    "                \"loss\": loss\n",
    "            }\n",
    "            \n",
    "            acc_metrics = {\n",
    "                \"class_acc\": float(pred_class_count)\n",
    "            }\n",
    "\n",
    "        return loss_metrics, acc_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../Datasets/Experiment\"\n",
    "src_folder = os.path.join(data_folder, \"Real World\")\n",
    "target_folder = os.path.join(data_folder, \"Product\")\n",
    "\n",
    "d = DataGenerator(\n",
    "    source_domain=src_folder,\n",
    "    target_domain=target_folder,\n",
    "    val_split=0.2,\n",
    "    test_split=0.2,\n",
    "    input_shape=(224,224),\n",
    "    target_labels=0.01,\n",
    "    target_train=False\n",
    ")\n",
    "\n",
    "train_label, train_nlabel = d.train_data()\n",
    "val = d.val_data()\n",
    "test = d.test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9bd77bd49d5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleDomainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_KL\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrisk_lambda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Semi-supervised (0.01)\n",
    "test_acc = []\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"Running test \", i)\n",
    "    \n",
    "    data_folder = \"../Datasets/Experiment\"\n",
    "    src_folder = os.path.join(data_folder, \"Real World\")\n",
    "    target_folder = os.path.join(data_folder, \"Product\")\n",
    "\n",
    "    d = DataGenerator(\n",
    "        source_domain=src_folder,\n",
    "        target_domain=target_folder,\n",
    "        val_split=0.2,\n",
    "        test_split=0.2,\n",
    "        input_shape=(224,224),\n",
    "        target_labels=0.01,\n",
    "        target_train=False\n",
    "    )\n",
    "\n",
    "    train_label, train_nlabel = d.train_data()\n",
    "    val = d.val_data()\n",
    "    test = d.test_data()\n",
    "    \n",
    "    m = SingleDomainModel(classes=len(d.classes), use_KL=False, risk_lambda=100, lr=1e-4)\n",
    "    _ = m.cuda()\n",
    "    m.train(100, train_label, val, patience=5, verbose=False)\n",
    "    loss, acc = m.evaluate(test)\n",
    "    test_acc.append(acc[\"class_acc\"])\n",
    "      \n",
    "print(np.mean(test_acc) * 100, np.std(test_acc) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "loss: 0.177308 encoder_loss: 0.10974 kl_loss: 0.064453 classifier_loss: 0.067568 \n",
      "joint_acc: 0.2537 class_acc: 0.3582 \n",
      "\n",
      "val_loss: 0.074571 val_kl_loss: 0.03339 val_classifier_loss: 0.041181 \n",
      "val_class_acc: 0.3182 \n",
      "\n",
      "Epoch 2\n",
      "loss: 0.162525 encoder_loss: 0.099491 kl_loss: 0.056398 classifier_loss: 0.063034 \n",
      "joint_acc: 0.4478 class_acc: 0.4776 \n",
      "\n",
      "val_loss: 0.0896 val_kl_loss: 0.049528 val_classifier_loss: 0.040072 \n",
      "val_class_acc: 0.4242 \n",
      "\n",
      "Epoch 3\n",
      "loss: 0.161081 encoder_loss: 0.101374 kl_loss: 0.060261 classifier_loss: 0.059707 \n",
      "joint_acc: 0.4813 class_acc: 0.5037 \n",
      "\n",
      "val_loss: 0.10817 val_kl_loss: 0.068367 val_classifier_loss: 0.039802 \n",
      "val_class_acc: 0.4848 \n",
      "\n",
      "Epoch 4\n",
      "loss: 0.1535 encoder_loss: 0.097124 kl_loss: 0.058439 classifier_loss: 0.056376 \n",
      "joint_acc: 0.5933 class_acc: 0.5672 \n",
      "\n",
      "val_loss: 0.088203 val_kl_loss: 0.048759 val_classifier_loss: 0.039444 \n",
      "val_class_acc: 0.4545 \n",
      "\n",
      "Epoch 5\n",
      "loss: 0.15364 encoder_loss: 0.098677 kl_loss: 0.060103 classifier_loss: 0.054964 \n",
      "joint_acc: 0.6455 class_acc: 0.6343 \n",
      "\n",
      "val_loss: 0.087433 val_kl_loss: 0.050538 val_classifier_loss: 0.036894 \n",
      "val_class_acc: 0.5606 \n",
      "\n",
      "Epoch 6\n",
      "loss: 0.144657 encoder_loss: 0.092262 kl_loss: 0.056676 classifier_loss: 0.052394 \n",
      "joint_acc: 0.6866 class_acc: 0.709 \n",
      "\n",
      "val_loss: 0.102803 val_kl_loss: 0.063229 val_classifier_loss: 0.039574 \n",
      "val_class_acc: 0.5303 \n",
      "\n",
      "loss: 0.062226 kl_loss: 0.038191 classifier_loss: 0.024035 \n",
      "class_acc: 0.2281 \n",
      "\n",
      "Running test  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "loss: 0.146327 encoder_loss: 0.080218 kl_loss: 0.034429 classifier_loss: 0.066109 \n",
      "joint_acc: 0.3134 class_acc: 0.3694 \n",
      "\n",
      "val_loss: 0.068905 val_kl_loss: 0.028131 val_classifier_loss: 0.040774 \n",
      "val_class_acc: 0.5 \n",
      "\n",
      "Epoch 2\n",
      "loss: 0.140177 encoder_loss: 0.077303 kl_loss: 0.033537 classifier_loss: 0.062873 \n",
      "joint_acc: 0.4627 class_acc: 0.4813 \n",
      "\n",
      "val_loss: 0.072675 val_kl_loss: 0.032475 val_classifier_loss: 0.040199 \n",
      "val_class_acc: 0.5758 \n",
      "\n",
      "Epoch 3\n",
      "loss: 0.137385 encoder_loss: 0.079685 kl_loss: 0.039227 classifier_loss: 0.057699 \n",
      "joint_acc: 0.5448 class_acc: 0.5336 \n",
      "\n",
      "val_loss: 0.07704 val_kl_loss: 0.041735 val_classifier_loss: 0.035305 \n",
      "val_class_acc: 0.5606 \n",
      "\n",
      "Epoch 4\n",
      "loss: 0.138768 encoder_loss: 0.084123 kl_loss: 0.045446 classifier_loss: 0.054645 \n",
      "joint_acc: 0.5709 class_acc: 0.5821 \n",
      "\n",
      "val_loss: 0.107962 val_kl_loss: 0.067441 val_classifier_loss: 0.04052 \n",
      "val_class_acc: 0.6061 \n",
      "\n",
      "Epoch 5\n",
      "loss: 0.141255 encoder_loss: 0.091334 kl_loss: 0.056763 classifier_loss: 0.049921 \n",
      "joint_acc: 0.6642 class_acc: 0.6679 \n",
      "\n",
      "val_loss: 0.081728 val_kl_loss: 0.041219 val_classifier_loss: 0.04051 \n",
      "val_class_acc: 0.5606 \n",
      "\n",
      "Epoch 6\n",
      "loss: 0.133471 encoder_loss: 0.084328 kl_loss: 0.05096 classifier_loss: 0.049142 \n",
      "joint_acc: 0.6679 class_acc: 0.6716 \n",
      "\n",
      "val_loss: 0.083161 val_kl_loss: 0.04933 val_classifier_loss: 0.033831 \n",
      "val_class_acc: 0.5455 \n",
      "\n",
      "loss: 0.059238 kl_loss: 0.03525 classifier_loss: 0.023987 \n",
      "class_acc: 0.2807 \n",
      "\n",
      "Running test  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "loss: 0.159871 encoder_loss: 0.089488 kl_loss: 0.043531 classifier_loss: 0.070383 \n",
      "joint_acc: 0.1306 class_acc: 0.3433 \n",
      "\n",
      "val_loss: 0.067729 val_kl_loss: 0.02536 val_classifier_loss: 0.042368 \n",
      "val_class_acc: 0.4394 \n",
      "\n",
      "Epoch 2\n",
      "loss: 0.155086 encoder_loss: 0.08891 kl_loss: 0.044492 classifier_loss: 0.066176 \n",
      "joint_acc: 0.3582 class_acc: 0.4776 \n",
      "\n",
      "val_loss: 0.089826 val_kl_loss: 0.048382 val_classifier_loss: 0.041444 \n",
      "val_class_acc: 0.5 \n",
      "\n",
      "Epoch 3\n",
      "loss: 0.148558 encoder_loss: 0.086318 kl_loss: 0.044105 classifier_loss: 0.06224 \n",
      "joint_acc: 0.4925 class_acc: 0.5373 \n",
      "\n",
      "val_loss: 0.091768 val_kl_loss: 0.055579 val_classifier_loss: 0.036189 \n",
      "val_class_acc: 0.5303 \n",
      "\n",
      "Epoch 4\n",
      "loss: 0.146714 encoder_loss: 0.088015 kl_loss: 0.048794 classifier_loss: 0.058699 \n",
      "joint_acc: 0.5896 class_acc: 0.6194 \n",
      "\n",
      "val_loss: 0.092392 val_kl_loss: 0.054549 val_classifier_loss: 0.037843 \n",
      "val_class_acc: 0.5758 \n",
      "\n",
      "Epoch 5\n",
      "loss: 0.150439 encoder_loss: 0.093278 kl_loss: 0.055563 classifier_loss: 0.057161 \n",
      "joint_acc: 0.6082 class_acc: 0.6381 \n",
      "\n",
      "val_loss: 0.094028 val_kl_loss: 0.052722 val_classifier_loss: 0.041306 \n",
      "val_class_acc: 0.5758 \n",
      "\n",
      "Epoch 6\n",
      "loss: 0.149483 encoder_loss: 0.096249 kl_loss: 0.061291 classifier_loss: 0.053234 \n",
      "joint_acc: 0.6903 class_acc: 0.7015 \n",
      "\n",
      "val_loss: 0.081777 val_kl_loss: 0.049836 val_classifier_loss: 0.031941 \n",
      "val_class_acc: 0.6667 \n",
      "\n",
      "loss: 0.068049 kl_loss: 0.044364 classifier_loss: 0.023686 \n",
      "class_acc: 0.4035 \n",
      "\n",
      "Running test  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "loss: 0.158332 encoder_loss: 0.090793 kl_loss: 0.045223 classifier_loss: 0.067539 \n",
      "joint_acc: 0.2649 class_acc: 0.403 \n",
      "\n",
      "val_loss: 0.113782 val_kl_loss: 0.074012 val_classifier_loss: 0.039771 \n",
      "val_class_acc: 0.4697 \n",
      "\n",
      "Epoch 2\n",
      "loss: 0.150117 encoder_loss: 0.086776 kl_loss: 0.04326 classifier_loss: 0.063341 \n",
      "joint_acc: 0.4552 class_acc: 0.5224 \n",
      "\n",
      "val_loss: 0.076447 val_kl_loss: 0.035906 val_classifier_loss: 0.04054 \n",
      "val_class_acc: 0.4848 \n",
      "\n",
      "Epoch 3\n",
      "loss: 0.14841 encoder_loss: 0.090254 kl_loss: 0.050187 classifier_loss: 0.058156 \n",
      "joint_acc: 0.5336 class_acc: 0.5597 \n",
      "\n",
      "val_loss: 0.084339 val_kl_loss: 0.048873 val_classifier_loss: 0.035465 \n",
      "val_class_acc: 0.4545 \n",
      "\n",
      "Epoch 4\n",
      "loss: 0.146339 encoder_loss: 0.091664 kl_loss: 0.054366 classifier_loss: 0.054675 \n",
      "joint_acc: 0.6269 class_acc: 0.6194 \n",
      "\n",
      "val_loss: 0.08603 val_kl_loss: 0.048313 val_classifier_loss: 0.037716 \n",
      "val_class_acc: 0.5606 \n",
      "\n",
      "Epoch 5\n",
      "loss: 0.141037 encoder_loss: 0.090649 kl_loss: 0.056539 classifier_loss: 0.050388 \n",
      "joint_acc: 0.6604 class_acc: 0.6679 \n",
      "\n",
      "val_loss: 0.103553 val_kl_loss: 0.071382 val_classifier_loss: 0.03217 \n",
      "val_class_acc: 0.5152 \n",
      "\n",
      "Epoch 6\n",
      "loss: 0.145751 encoder_loss: 0.096977 kl_loss: 0.063279 classifier_loss: 0.048774 \n",
      "joint_acc: 0.6978 class_acc: 0.6791 \n",
      "\n",
      "val_loss: 0.111378 val_kl_loss: 0.072665 val_classifier_loss: 0.038714 \n",
      "val_class_acc: 0.5455 \n",
      "\n",
      "Epoch 7\n",
      "loss: 0.142049 encoder_loss: 0.095484 kl_loss: 0.064618 classifier_loss: 0.046565 \n",
      "joint_acc: 0.709 class_acc: 0.7313 \n",
      "\n",
      "val_loss: 0.095403 val_kl_loss: 0.057706 val_classifier_loss: 0.037697 \n",
      "val_class_acc: 0.6515 \n",
      "\n",
      "loss: 0.066721 kl_loss: 0.044019 classifier_loss: 0.022701 \n",
      "class_acc: 0.386 \n",
      "\n",
      "Running test  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "loss: 0.149624 encoder_loss: 0.081595 kl_loss: 0.035979 classifier_loss: 0.068029 \n",
      "joint_acc: 0.1642 class_acc: 0.2649 \n",
      "\n",
      "val_loss: 0.067711 val_kl_loss: 0.025757 val_classifier_loss: 0.041954 \n",
      "val_class_acc: 0.4394 \n",
      "\n",
      "Epoch 2\n",
      "loss: 0.156101 encoder_loss: 0.091654 kl_loss: 0.047732 classifier_loss: 0.064446 \n",
      "joint_acc: 0.3769 class_acc: 0.4403 \n",
      "\n",
      "val_loss: 0.088684 val_kl_loss: 0.052654 val_classifier_loss: 0.036029 \n",
      "val_class_acc: 0.5303 \n",
      "\n",
      "Epoch 3\n",
      "loss: 0.151757 encoder_loss: 0.091917 kl_loss: 0.051015 classifier_loss: 0.05984 \n",
      "joint_acc: 0.5373 class_acc: 0.541 \n",
      "\n",
      "val_loss: 0.084725 val_kl_loss: 0.047977 val_classifier_loss: 0.036747 \n",
      "val_class_acc: 0.5909 \n",
      "\n",
      "Epoch 4\n",
      "loss: 0.145814 encoder_loss: 0.089565 kl_loss: 0.051696 classifier_loss: 0.056249 \n",
      "joint_acc: 0.5821 class_acc: 0.5896 \n",
      "\n",
      "val_loss: 0.077818 val_kl_loss: 0.041716 val_classifier_loss: 0.036103 \n",
      "val_class_acc: 0.5758 \n",
      "\n",
      "Epoch 5\n",
      "loss: 0.146107 encoder_loss: 0.094023 kl_loss: 0.059147 classifier_loss: 0.052084 \n",
      "joint_acc: 0.653 class_acc: 0.653 \n",
      "\n",
      "val_loss: 0.080668 val_kl_loss: 0.047816 val_classifier_loss: 0.032852 \n",
      "val_class_acc: 0.6061 \n",
      "\n",
      "Epoch 6\n",
      "loss: 0.143405 encoder_loss: 0.093502 kl_loss: 0.060357 classifier_loss: 0.049904 \n",
      "joint_acc: 0.6866 class_acc: 0.694 \n",
      "\n",
      "val_loss: 0.115839 val_kl_loss: 0.080821 val_classifier_loss: 0.035018 \n",
      "val_class_acc: 0.6212 \n",
      "\n",
      "loss: 0.053806 kl_loss: 0.029828 classifier_loss: 0.023978 \n",
      "class_acc: 0.3333 \n",
      "\n",
      "32.631578947368425 6.5266930658730775\n"
     ]
    }
   ],
   "source": [
    "# Semi-supervised (0.01) w/ KL\n",
    "test_acc = []\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"Running test \", i)\n",
    "    \n",
    "    data_folder = \"../Datasets/Experiment\"\n",
    "    src_folder = os.path.join(data_folder, \"Real World\")\n",
    "    target_folder = os.path.join(data_folder, \"Product\")\n",
    "\n",
    "    d = DataGenerator(\n",
    "        source_domain=src_folder,\n",
    "        target_domain=target_folder,\n",
    "        val_split=0.2,\n",
    "        test_split=0.2,\n",
    "        input_shape=(224,224),\n",
    "        target_labels=0.01,\n",
    "        target_train=False\n",
    "    )\n",
    "\n",
    "    train_label, train_nlabel = d.train_data()\n",
    "    val = d.val_data()\n",
    "    test = d.test_data()\n",
    "    \n",
    "    m = SingleDomainModel(classes=len(d.classes), use_KL=True, risk_lambda=20, lr=1e-4)\n",
    "    _ = m.cuda()\n",
    "    m.train(100, train_label, val, patience=5, verbose=True)\n",
    "    loss, acc = m.evaluate(test)\n",
    "    test_acc.append(acc[\"class_acc\"])\n",
    "    \n",
    "print(np.mean(test_acc) * 100, np.std(test_acc) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.064281 kl_loss: 0.023097 classifier_loss: 0.041184 \n",
      "class_acc: 0.5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss, acc = m.evaluate(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.023817 \n",
      "class_acc: 0.4035 \n",
      "\n",
      "Running test  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.022466 \n",
      "class_acc: 0.3509 \n",
      "\n",
      "Running test  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.019324 \n",
      "class_acc: 0.5088 \n",
      "\n",
      "Running test  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.026238 \n",
      "class_acc: 0.5614 \n",
      "\n",
      "Running test  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.022996 \n",
      "class_acc: 0.4386 \n",
      "\n",
      "45.263157894736835 7.476237106197374\n"
     ]
    }
   ],
   "source": [
    "# Semi-supervised (0.25)\n",
    "test_acc = []\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"Running test \", i)\n",
    "    \n",
    "    data_folder = \"../Datasets/Experiment\"\n",
    "    src_folder = os.path.join(data_folder, \"Real World\")\n",
    "    target_folder = os.path.join(data_folder, \"Product\")\n",
    "\n",
    "    d = DataGenerator(\n",
    "        source_domain=src_folder,\n",
    "        target_domain=target_folder,\n",
    "        val_split=0.2,\n",
    "        test_split=0.2,\n",
    "        input_shape=(224,224),\n",
    "        target_labels=0.25,\n",
    "        target_train=False\n",
    "    )\n",
    "\n",
    "    train_label, train_nlabel = d.train_data()\n",
    "    val = d.val_data()\n",
    "    test = d.test_data()\n",
    "    \n",
    "    m = SingleDomainModel(classes=len(d.classes), use_KL=False, risk_lambda=10, lr=1e-4)\n",
    "    _ = m.cuda()\n",
    "    m.train(100, train_label, val, patience=5, verbose=False)\n",
    "    loss, acc = m.evaluate(test)\n",
    "    test_acc.append(acc[\"class_acc\"])\n",
    "    \n",
    "print(np.mean(test_acc) * 100, np.std(test_acc) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.043372 kl_loss: 0.023189 classifier_loss: 0.020182 \n",
      "class_acc: 0.5614 \n",
      "\n",
      "Running test  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.047863 kl_loss: 0.030153 classifier_loss: 0.01771 \n",
      "class_acc: 0.6316 \n",
      "\n",
      "Running test  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.055563 kl_loss: 0.038938 classifier_loss: 0.016625 \n",
      "class_acc: 0.6491 \n",
      "\n",
      "Running test  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.046911 kl_loss: 0.0273 classifier_loss: 0.019611 \n",
      "class_acc: 0.4912 \n",
      "\n",
      "Running test  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.067079 kl_loss: 0.048827 classifier_loss: 0.018251 \n",
      "class_acc: 0.6491 \n",
      "\n",
      "59.64912280701753 6.1778304777750925\n"
     ]
    }
   ],
   "source": [
    "# Semi-supervised (0.25) w/ KL\n",
    "test_acc = []\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"Running test \", i)\n",
    "    \n",
    "    data_folder = \"../Datasets/Experiment\"\n",
    "    src_folder = os.path.join(data_folder, \"Real World\")\n",
    "    target_folder = os.path.join(data_folder, \"Product\")\n",
    "\n",
    "    d = DataGenerator(\n",
    "        source_domain=src_folder,\n",
    "        target_domain=target_folder,\n",
    "        val_split=0.2,\n",
    "        test_split=0.2,\n",
    "        input_shape=(224,224),\n",
    "        target_labels=0.25,\n",
    "        target_train=False\n",
    "    )\n",
    "\n",
    "    train_label, train_nlabel = d.train_data()\n",
    "    val = d.val_data()\n",
    "    test = d.test_data()\n",
    "    \n",
    "    m = SingleDomainModel(classes=len(d.classes), use_KL=True, risk_lambda=10, lr=1e-4)\n",
    "    _ = m.cuda()\n",
    "    m.train(100, train_label, val, patience=5, verbose=False)\n",
    "    loss, acc = m.evaluate(test)\n",
    "    test_acc.append(acc[\"class_acc\"])\n",
    "    \n",
    "print(np.mean(test_acc) * 100, np.std(test_acc) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.016326 \n",
      "class_acc: 0.6316 \n",
      "\n",
      "Running test  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.019363 \n",
      "class_acc: 0.5439 \n",
      "\n",
      "Running test  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.019644 \n",
      "class_acc: 0.614 \n",
      "\n",
      "Running test  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.022749 \n",
      "class_acc: 0.4386 \n",
      "\n",
      "Running test  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.015867 \n",
      "class_acc: 0.6316 \n",
      "\n",
      "57.19298245614036 7.4100744147167985\n"
     ]
    }
   ],
   "source": [
    "# Semi-supervised (0.4)\n",
    "test_acc = []\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"Running test \", i)\n",
    "    \n",
    "    data_folder = \"../Datasets/Experiment\"\n",
    "    src_folder = os.path.join(data_folder, \"Real World\")\n",
    "    target_folder = os.path.join(data_folder, \"Product\")\n",
    "\n",
    "    d = DataGenerator(\n",
    "        source_domain=src_folder,\n",
    "        target_domain=target_folder,\n",
    "        val_split=0.2,\n",
    "        test_split=0.2,\n",
    "        input_shape=(224,224),\n",
    "        target_labels=0.4,\n",
    "        target_train=False\n",
    "    )\n",
    "\n",
    "    train_label, train_nlabel = d.train_data()\n",
    "    val = d.val_data()\n",
    "    test = d.test_data()\n",
    "    \n",
    "    m = SingleDomainModel(classes=len(d.classes), use_KL=False, risk_lambda=10, lr=1e-4)\n",
    "    _ = m.cuda()\n",
    "    m.train(100, train_label, val, patience=5, verbose=False)\n",
    "    loss, acc = m.evaluate(test)\n",
    "    test_acc.append(acc[\"class_acc\"])\n",
    "    \n",
    "print(np.mean(test_acc) * 100, np.std(test_acc) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.048692 kl_loss: 0.030309 classifier_loss: 0.018383 \n",
      "class_acc: 0.5789 \n",
      "\n",
      "Running test  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.042661 kl_loss: 0.025382 classifier_loss: 0.017279 \n",
      "class_acc: 0.6316 \n",
      "\n",
      "Running test  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.039603 kl_loss: 0.022554 classifier_loss: 0.017049 \n",
      "class_acc: 0.6667 \n",
      "\n",
      "Running test  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.038365 kl_loss: 0.022904 classifier_loss: 0.015461 \n",
      "class_acc: 0.6842 \n",
      "\n",
      "Running test  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.04148 kl_loss: 0.020299 classifier_loss: 0.021181 \n",
      "class_acc: 0.4737 \n",
      "\n",
      "60.70175438596491 7.57439759470979\n"
     ]
    }
   ],
   "source": [
    "# Semi-supervised (0.4) w/ KL\n",
    "test_acc = []\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"Running test \", i)\n",
    "    \n",
    "    data_folder = \"../Datasets/Experiment\"\n",
    "    src_folder = os.path.join(data_folder, \"Real World\")\n",
    "    target_folder = os.path.join(data_folder, \"Product\")\n",
    "\n",
    "    d = DataGenerator(\n",
    "        source_domain=src_folder,\n",
    "        target_domain=target_folder,\n",
    "        val_split=0.2,\n",
    "        test_split=0.2,\n",
    "        input_shape=(224,224),\n",
    "        target_labels=0.4,\n",
    "        target_train=False\n",
    "    )\n",
    "\n",
    "    train_label, train_nlabel = d.train_data()\n",
    "    val = d.val_data()\n",
    "    test = d.test_data()\n",
    "    \n",
    "    m = SingleDomainModel(classes=len(d.classes), use_KL=True, risk_lambda=10, lr=1e-4)\n",
    "    _ = m.cuda()\n",
    "    m.train(100, train_label, val, patience=5, verbose=False)\n",
    "    loss, acc = m.evaluate(test)\n",
    "    test_acc.append(acc[\"class_acc\"])\n",
    "    \n",
    "print(np.mean(test_acc) * 100, np.std(test_acc) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.019813 \n",
      "class_acc: 0.5789 \n",
      "\n",
      "Running test  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.020217 \n",
      "class_acc: 0.7193 \n",
      "\n",
      "Running test  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.022502 \n",
      "class_acc: 0.4912 \n",
      "\n",
      "Running test  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.016603 \n",
      "class_acc: 0.6842 \n",
      "\n",
      "Running test  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.012666 \n",
      "class_acc: 0.7193 \n",
      "\n",
      "63.859649122807014 8.986841034993473\n"
     ]
    }
   ],
   "source": [
    "# Semi-supervised (0.7)\n",
    "test_acc = []\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"Running test \", i)\n",
    "    \n",
    "    data_folder = \"../Datasets/Experiment\"\n",
    "    src_folder = os.path.join(data_folder, \"Real World\")\n",
    "    target_folder = os.path.join(data_folder, \"Product\")\n",
    "\n",
    "    d = DataGenerator(\n",
    "        source_domain=src_folder,\n",
    "        target_domain=target_folder,\n",
    "        val_split=0.2,\n",
    "        test_split=0.2,\n",
    "        input_shape=(224,224),\n",
    "        target_labels=0.7,\n",
    "        target_train=False\n",
    "    )\n",
    "\n",
    "    train_label, train_nlabel = d.train_data()\n",
    "    val = d.val_data()\n",
    "    test = d.test_data()\n",
    "    \n",
    "    m = SingleDomainModel(classes=len(d.classes), use_KL=False, risk_lambda=10, lr=1e-4)\n",
    "    _ = m.cuda()\n",
    "    m.train(100, train_label, val, patience=5, verbose=False)\n",
    "    loss, acc = m.evaluate(test)\n",
    "    test_acc.append(acc[\"class_acc\"])\n",
    "    \n",
    "print(np.mean(test_acc) * 100, np.std(test_acc) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.019904 kl_loss: 0.003167 classifier_loss: 0.016737 \n",
      "class_acc: 0.6667 \n",
      "\n",
      "Running test  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.019611 kl_loss: 0.004195 classifier_loss: 0.015416 \n",
      "class_acc: 0.7018 \n",
      "\n",
      "Running test  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.019451 kl_loss: 0.003528 classifier_loss: 0.015922 \n",
      "class_acc: 0.6842 \n",
      "\n",
      "Running test  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.022677 kl_loss: 0.004684 classifier_loss: 0.017993 \n",
      "class_acc: 0.614 \n",
      "\n",
      "Running test  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.018521 kl_loss: 0.00377 classifier_loss: 0.014751 \n",
      "class_acc: 0.7193 \n",
      "\n",
      "67.71929824561404 3.6125018038550873\n"
     ]
    }
   ],
   "source": [
    "# Semi-supervised (0.7) w/ KL\n",
    "test_acc = []\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"Running test \", i)\n",
    "    \n",
    "    data_folder = \"../Datasets/Experiment\"\n",
    "    src_folder = os.path.join(data_folder, \"Real World\")\n",
    "    target_folder = os.path.join(data_folder, \"Product\")\n",
    "\n",
    "    d = DataGenerator(\n",
    "        source_domain=src_folder,\n",
    "        target_domain=target_folder,\n",
    "        val_split=0.2,\n",
    "        test_split=0.2,\n",
    "        input_shape=(224,224),\n",
    "        target_labels=0.7,\n",
    "        target_train=False\n",
    "    )\n",
    "\n",
    "    train_label, train_nlabel = d.train_data()\n",
    "    val = d.val_data()\n",
    "    test = d.test_data()\n",
    "    \n",
    "    m = SingleDomainModel(classes=len(d.classes), use_KL=True, risk_lambda=1, lr=1e-4)\n",
    "    _ = m.cuda()\n",
    "    m.train(100, train_label, val, patience=5, verbose=False)\n",
    "    loss, acc = m.evaluate(test)\n",
    "    test_acc.append(acc[\"class_acc\"])\n",
    "    \n",
    "print(np.mean(test_acc) * 100, np.std(test_acc) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.017985 \n",
      "class_acc: 0.6316 \n",
      "\n",
      "Running test  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.016293 \n",
      "class_acc: 0.7018 \n",
      "\n",
      "Running test  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.016969 \n",
      "class_acc: 0.6491 \n",
      "\n",
      "Running test  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.014453 \n",
      "class_acc: 0.7719 \n",
      "\n",
      "Running test  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.017657 \n",
      "class_acc: 0.614 \n",
      "\n",
      "67.36842105263159 5.722633835193012\n"
     ]
    }
   ],
   "source": [
    "# Semi-supervised (1.0)\n",
    "test_acc = []\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"Running test \", i)\n",
    "    \n",
    "    data_folder = \"../Datasets/Experiment\"\n",
    "    src_folder = os.path.join(data_folder, \"Real World\")\n",
    "    target_folder = os.path.join(data_folder, \"Product\")\n",
    "\n",
    "    d = DataGenerator(\n",
    "        source_domain=src_folder,\n",
    "        target_domain=target_folder,\n",
    "        val_split=0.2,\n",
    "        test_split=0.2,\n",
    "        input_shape=(224,224),\n",
    "        target_labels=1,\n",
    "        target_train=False\n",
    "    )\n",
    "\n",
    "    train_label, train_nlabel = d.train_data()\n",
    "    val = d.val_data()\n",
    "    test = d.test_data()\n",
    "    \n",
    "    m = SingleDomainModel(classes=len(d.classes), use_KL=False, risk_lambda=10, lr=1e-4)\n",
    "    _ = m.cuda()\n",
    "    m.train(100, train_label, val, patience=5, verbose=False)\n",
    "    loss, acc = m.evaluate(test)\n",
    "    test_acc.append(acc[\"class_acc\"])\n",
    "    \n",
    "print(np.mean(test_acc) * 100, np.std(test_acc) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.01384 kl_loss: 0.004638 classifier_loss: 0.009202 \n",
      "class_acc: 0.7895 \n",
      "\n",
      "Running test  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.01908 kl_loss: 0.003915 classifier_loss: 0.015165 \n",
      "class_acc: 0.7018 \n",
      "\n",
      "Running test  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.017607 kl_loss: 0.004642 classifier_loss: 0.012965 \n",
      "class_acc: 0.7544 \n",
      "\n",
      "Running test  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.017084 kl_loss: 0.003548 classifier_loss: 0.013536 \n",
      "class_acc: 0.7368 \n",
      "\n",
      "Running test  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.015197 kl_loss: 0.002888 classifier_loss: 0.012309 \n",
      "class_acc: 0.807 \n",
      "\n",
      "75.78947368421052 3.7463432463267767\n"
     ]
    }
   ],
   "source": [
    "# Semi-supervised (1.0) w/ KL\n",
    "test_acc = []\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"Running test \", i)\n",
    "    \n",
    "    data_folder = \"../Datasets/Experiment\"\n",
    "    src_folder = os.path.join(data_folder, \"Real World\")\n",
    "    target_folder = os.path.join(data_folder, \"Product\")\n",
    "\n",
    "    d = DataGenerator(\n",
    "        source_domain=src_folder,\n",
    "        target_domain=target_folder,\n",
    "        val_split=0.2,\n",
    "        test_split=0.2,\n",
    "        input_shape=(224,224),\n",
    "        target_labels=1.0,\n",
    "        target_train=False\n",
    "    )\n",
    "\n",
    "    train_label, train_nlabel = d.train_data()\n",
    "    val = d.val_data()\n",
    "    test = d.test_data()\n",
    "    \n",
    "    m = SingleDomainModel(classes=len(d.classes), use_KL=True, risk_lambda=1, lr=1e-4)\n",
    "    _ = m.cuda()\n",
    "    m.train(100, train_label, val, patience=5, verbose=False)\n",
    "    loss, acc = m.evaluate(test)\n",
    "    test_acc.append(acc[\"class_acc\"])\n",
    "    \n",
    "print(np.mean(test_acc) * 100, np.std(test_acc) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "loss=0.0448097315912823, kl_loss=0.0031949610505652474, pred_loss=0.029040276423299986, dis_loss=0.012574494669311926, joint_acc=0.21428571428571427, class_acc=0.37714285714285717, dis_acc=0.5984405458089669\n",
      "\n",
      "val_loss=0.08116570048862033, val_kl_loss=0.0034040855036841498, val_pred_loss=0.030469600359598795, val_dis_loss=0.04729201528761122, val_joint_acc=0.044444444444444446, val_class_acc=0.28888888888888886, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.0665176458526076, test_kl_loss=0.004598480044749745, test_pred_loss=0.02362041515216493, test_dis_loss=0.03829875326993173, test_joint_acc=0.03508771929824561, test_class_acc=0.40350877192982454, test_dis_acc=0.0\n",
      "\n",
      "Epoch 2\n",
      "loss=0.046705354026883666, kl_loss=0.002489541328673707, pred_loss=0.028486819527534946, dis_loss=0.015728992328309176, joint_acc=0.22285714285714286, class_acc=0.3657142857142857, dis_acc=0.5458089668615984\n",
      "\n",
      "val_loss=0.0897398206922743, val_kl_loss=0.005053795377413432, val_pred_loss=0.02954330179426405, val_dis_loss=0.05514272583855523, val_joint_acc=0.17777777777777778, val_class_acc=0.35555555555555557, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.0712764723259106, test_kl_loss=0.0037328224433095833, test_pred_loss=0.023306045615882204, test_dis_loss=0.04423760531241434, test_joint_acc=0.2807017543859649, test_class_acc=0.3684210526315789, test_dis_acc=0.0\n",
      "\n",
      "Epoch 3\n",
      "loss=0.048656032099361306, kl_loss=0.0022763815830093145, pred_loss=0.027418718003390127, dis_loss=0.018960932135349592, joint_acc=0.2914285714285714, class_acc=0.4685714285714286, dis_acc=0.6296296296296297\n",
      "\n",
      "val_loss=0.07420233090718588, val_kl_loss=0.0015501073665089076, val_pred_loss=0.02914564079708523, val_dis_loss=0.04350658257802328, val_joint_acc=0.022222222222222223, val_class_acc=0.26666666666666666, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.06069182513052957, test_kl_loss=0.002316343156914962, test_pred_loss=0.02219285253892865, test_dis_loss=0.036182629434685955, test_joint_acc=0.0, test_class_acc=0.45614035087719296, test_dis_acc=0.0\n",
      "\n",
      "Epoch 4\n",
      "loss=0.0434258509332906, kl_loss=0.0018913252006845865, pred_loss=0.024550543542493853, dis_loss=0.016983982299038775, joint_acc=0.42857142857142855, class_acc=0.5428571428571428, dis_acc=0.6198830409356725\n",
      "\n",
      "val_loss=0.07541827095879448, val_kl_loss=0.002088767621252272, val_pred_loss=0.02545179261101617, val_dis_loss=0.04787771436903212, val_joint_acc=0.24444444444444444, val_class_acc=0.4888888888888889, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.06007429591396399, test_kl_loss=0.002007199353293369, test_pred_loss=0.018514505603857208, test_dis_loss=0.039552588211862666, test_joint_acc=0.14035087719298245, test_class_acc=0.631578947368421, test_dis_acc=0.0\n",
      "\n",
      "Epoch 5\n",
      "loss=0.040247909971612705, kl_loss=0.001809024671364946, pred_loss=0.021667219625811363, dis_loss=0.0167716642220815, joint_acc=0.5142857142857142, class_acc=0.5857142857142857, dis_acc=0.6042884990253411\n",
      "\n",
      "val_loss=0.0850806819068061, val_kl_loss=0.0020191659530003864, val_pred_loss=0.028407213422987194, val_dis_loss=0.054654301537407766, val_joint_acc=0.0, val_class_acc=0.4222222222222222, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.06465114626968116, test_kl_loss=0.002332663849780434, test_pred_loss=0.017793084445752595, test_dis_loss=0.04452539745130037, test_joint_acc=0.017543859649122806, test_class_acc=0.5789473684210527, test_dis_acc=0.0\n",
      "\n",
      "Epoch 6\n",
      "loss=0.037661203166894745, kl_loss=0.0013843670806921945, pred_loss=0.0187097486929122, dis_loss=0.017567087451384546, joint_acc=0.6057142857142858, class_acc=0.6685714285714286, dis_acc=0.5886939571150097\n",
      "\n",
      "val_loss=0.06816716723971897, val_kl_loss=0.001136200295554267, val_pred_loss=0.02545767625172933, val_dis_loss=0.041573291354709205, val_joint_acc=0.0, val_class_acc=0.4888888888888889, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.0525870072214227, test_kl_loss=0.001355193163219251, test_pred_loss=0.016837631401262786, test_dis_loss=0.0343941847483317, test_joint_acc=0.017543859649122806, test_class_acc=0.631578947368421, test_dis_acc=0.0\n",
      "\n",
      "Epoch 7\n",
      "loss=0.03329771606080946, kl_loss=0.0012013681058646642, pred_loss=0.016667807776096038, dis_loss=0.01542854001182794, joint_acc=0.64, class_acc=0.6971428571428572, dis_acc=0.594541910331384\n",
      "\n",
      "val_loss=0.07660190794203016, val_kl_loss=0.0012609745065371195, val_pred_loss=0.02525286144680447, val_dis_loss=0.05008807182312012, val_joint_acc=0.0, val_class_acc=0.5111111111111111, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.06014289772301389, test_kl_loss=0.0014261080507646526, test_pred_loss=0.01686186016651622, test_dis_loss=0.041854929505733024, test_joint_acc=0.0, test_class_acc=0.6842105263157895, test_dis_acc=0.0\n",
      "\n",
      "Epoch 8\n",
      "loss=0.033196084215859456, kl_loss=0.0009850375644760987, pred_loss=0.015402074329569557, dis_loss=0.016808971791704264, joint_acc=0.7085714285714285, class_acc=0.7542857142857143, dis_acc=0.5847953216374269\n",
      "\n",
      "val_loss=0.07973314921061198, val_kl_loss=0.0014683052897453309, val_pred_loss=0.028694860140482583, val_dis_loss=0.04956998295254177, val_joint_acc=0.0, val_class_acc=0.5333333333333333, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.06164452904149106, test_kl_loss=0.0020759748785119307, test_pred_loss=0.01904078115496719, test_dis_loss=0.04052777039377313, test_joint_acc=0.0, test_class_acc=0.5789473684210527, test_dis_acc=0.0\n",
      "\n",
      "Epoch 9\n",
      "loss=0.028334730317485728, kl_loss=0.0010738557397041173, pred_loss=0.012251448561573586, dis_loss=0.015009425740260594, joint_acc=0.7457142857142857, class_acc=0.7857142857142857, dis_acc=0.6003898635477583\n",
      "\n",
      "val_loss=0.11072650485568576, val_kl_loss=0.0018668350246217515, val_pred_loss=0.03665362728966607, val_dis_loss=0.07220603624979655, val_joint_acc=0.0, val_class_acc=0.4888888888888889, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.07980321582994963, test_kl_loss=0.0016129147588161, test_pred_loss=0.019651157814159728, test_dis_loss=0.05853914377982156, test_joint_acc=0.0, test_class_acc=0.6666666666666666, test_dis_acc=0.0\n",
      "\n",
      "Epoch 10\n",
      "loss=0.029754595217416625, kl_loss=0.000896470508670714, pred_loss=0.00985821785285459, dis_loss=0.01899990706648278, joint_acc=0.7828571428571428, class_acc=0.8228571428571428, dis_acc=0.6393762183235867\n",
      "\n",
      "val_loss=0.07592148251003689, val_kl_loss=0.0008917099899715847, val_pred_loss=0.029050050841437445, val_dis_loss=0.04597972234090169, val_joint_acc=0.0, val_class_acc=0.5333333333333333, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.05964988156368858, test_kl_loss=0.0010141021849816305, test_pred_loss=0.020596550222028765, test_dis_loss=0.038039228372406544, test_joint_acc=0.0, test_class_acc=0.6491228070175439, test_dis_acc=0.0\n",
      "\n",
      "Epoch 11\n",
      "loss=0.022899388686025816, kl_loss=0.0004781368869351365, pred_loss=0.007527373135670816, dis_loss=0.01489387862166466, joint_acc=0.8171428571428572, class_acc=0.8571428571428571, dis_acc=0.5925925925925926\n",
      "\n",
      "val_loss=0.09254517025417752, val_kl_loss=0.0006386371536387337, val_pred_loss=0.03393683433532715, val_dis_loss=0.05796970261467828, val_joint_acc=0.0, val_class_acc=0.5555555555555556, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.07798187356246145, test_kl_loss=0.0009637916166531412, test_pred_loss=0.029617698569046825, test_dis_loss=0.047400382527133876, test_joint_acc=0.0, test_class_acc=0.5087719298245614, test_dis_acc=0.0\n",
      "\n",
      "Epoch 12\n",
      "loss=0.022415539906968384, kl_loss=0.0003342090435979659, pred_loss=0.005855033170526255, dis_loss=0.01622629795971437, joint_acc=0.8714285714285714, class_acc=0.9171428571428571, dis_acc=0.6062378167641326\n",
      "\n",
      "val_loss=0.08855360878838434, val_kl_loss=0.0005675886240270403, val_pred_loss=0.0255475918451945, val_dis_loss=0.06243842442830404, val_joint_acc=0.0, val_class_acc=0.7111111111111111, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.0780988241496839, test_kl_loss=0.000625220764624445, test_pred_loss=0.026181745947453015, test_dis_loss=0.05129185894079376, test_joint_acc=0.0, test_class_acc=0.5789473684210527, test_dis_acc=0.0\n",
      "\n",
      "Epoch 13\n",
      "loss=0.024290626044394213, kl_loss=0.00027747281244275165, pred_loss=0.006502265019839735, dis_loss=0.017510888375501653, joint_acc=0.8571428571428571, class_acc=0.9, dis_acc=0.6159844054580896\n",
      "\n",
      "val_loss=0.10593795776367188, val_kl_loss=0.00038021562827958, val_pred_loss=0.039247711499532066, val_dis_loss=0.0663100348578559, val_joint_acc=0.0, val_class_acc=0.5333333333333333, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.08626382392749452, test_kl_loss=0.00041132289589497083, test_pred_loss=0.031120126707512036, test_dis_loss=0.05473237288625617, test_joint_acc=0.0, test_class_acc=0.5964912280701754, test_dis_acc=0.0\n",
      "\n",
      "Epoch 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=0.024398054237718934, kl_loss=0.00020799190613856905, pred_loss=0.005284243922310266, dis_loss=0.018905818375230532, joint_acc=0.8828571428571429, class_acc=0.9314285714285714, dis_acc=0.6257309941520468\n",
      "\n",
      "val_loss=0.09120824601915148, val_kl_loss=0.0002967918084727393, val_pred_loss=0.037303956349690755, val_dis_loss=0.05360750092400445, val_joint_acc=0.0, val_class_acc=0.6222222222222222, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.07948094083551775, test_kl_loss=0.0002799253061152341, test_pred_loss=0.03591607746325041, test_dis_loss=0.043284934863709566, test_joint_acc=0.0, test_class_acc=0.5614035087719298, test_dis_acc=0.0\n",
      "\n",
      "Epoch 15\n",
      "loss=0.02136706928295931, kl_loss=8.285282108003227e-05, pred_loss=0.004353846802755639, dis_loss=0.01693036966388918, joint_acc=0.8857142857142857, class_acc=0.9342857142857143, dis_acc=0.6042884990253411\n",
      "\n",
      "val_loss=0.08339019351535373, val_kl_loss=0.00023287754091951582, val_pred_loss=0.03308609591590034, val_dis_loss=0.050071223576863604, val_joint_acc=0.0, val_class_acc=0.6666666666666666, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.07373159810116417, test_kl_loss=0.00032160110902367976, test_pred_loss=0.031892864327681694, test_dis_loss=0.041517132206967004, test_joint_acc=0.0, test_class_acc=0.5964912280701754, test_dis_acc=0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "use_KL=True\n",
    "\n",
    "for p in m.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(f\"Epoch {i+1}\")\n",
    "    \n",
    "    loss, kl_loss, pred_loss, dis_loss, nlab_total = (0,0,0,0,0) \n",
    "    pred_count_joint, pred_count_class, dis_count, lab_total = (0,0,0,0)\n",
    "    \n",
    "    for batch_label, batch_nlabel in itertools.zip_longest(train_label, train_nlabel):\n",
    "        \n",
    "        if batch_label is not None:\n",
    "            labels = batch_label[1]\n",
    "            \n",
    "            if batch_nlabel is not None:\n",
    "                imgs = torch.cat((batch_label[0], batch_nlabel), 0)\n",
    "            else:\n",
    "                imgs = batch_label[0]\n",
    "        else:\n",
    "            imgs = batch_nlabel\n",
    "            labels = None\n",
    "                \n",
    "        batch_results = m.run_batch(imgs, labels, use_KL=use_KL, rep_loss=rep_loss, risk_loss=risk_loss)\n",
    "        loss += batch_results[0]\n",
    "        kl_loss += batch_results[1]\n",
    "        pred_loss += batch_results[2]\n",
    "        dis_loss += batch_results[3]\n",
    "        pred_count_joint += batch_results[4]\n",
    "        pred_count_class += batch_results[5]\n",
    "        dis_count += batch_results[6]\n",
    "        \n",
    "        if batch_label is not None:\n",
    "            lab_total += batch_label[1].shape[0]\n",
    "        if batch_nlabel is not None:\n",
    "            nlab_total += batch_nlabel.shape[0]\n",
    "    total = lab_total + nlab_total\n",
    "        \n",
    "    print(f\"loss={loss/total}, \"\n",
    "          f\"kl_loss={kl_loss/total}, \" \n",
    "          f\"pred_loss={pred_loss/total}, \"\n",
    "          f\"dis_loss={dis_loss/total}, \"\n",
    "          f\"joint_acc={pred_count_joint/lab_total}, \"\n",
    "          f\"class_acc={pred_count_class/lab_total}, \"\n",
    "          f\"dis_acc={dis_count/total}\"\n",
    "         )\n",
    "    print()\n",
    "    \n",
    "    loss, kl_loss, pred_loss, dis_loss, total = (0,0,0,0,0) \n",
    "    pred_count_joint, pred_count_class, dis_count = (0,0,0)\n",
    "    \n",
    "    for data in val:    \n",
    "        imgs, labels = data   \n",
    "        batch_results = m.run_batch(imgs, labels, training=False, use_KL=use_KL, rep_loss=rep_loss, risk_loss=risk_loss)\n",
    "        loss += batch_results[0]\n",
    "        kl_loss += batch_results[1]\n",
    "        pred_loss += batch_results[2]\n",
    "        dis_loss += batch_results[3]\n",
    "        pred_count_joint += batch_results[4]\n",
    "        pred_count_class += batch_results[5]\n",
    "        dis_count += batch_results[6]\n",
    "        total += data[1].shape[0]  \n",
    "            \n",
    "    print(f\"val_loss={loss/total}, \"\n",
    "          f\"val_kl_loss={kl_loss/total}, \" \n",
    "          f\"val_pred_loss={pred_loss/total}, \"\n",
    "          f\"val_dis_loss={dis_loss/total}, \"\n",
    "          f\"val_joint_acc={pred_count_joint/total}, \"\n",
    "          f\"val_class_acc={pred_count_class/total}, \"\n",
    "          f\"val_dis_acc={dis_count/total}\"\n",
    "         )\n",
    "    print()\n",
    "\n",
    "    \n",
    "    loss, kl_loss, pred_loss, dis_loss, total = (0,0,0,0,0) \n",
    "    pred_count_joint, pred_count_class, dis_count = (0,0,0)\n",
    "    for data in test:\n",
    "        imgs, labels = data\n",
    "        batch_results = m.run_batch(imgs, labels, training=False, use_KL=use_KL, rep_loss=rep_loss, risk_loss=risk_loss)\n",
    "        loss += batch_results[0]\n",
    "        kl_loss += batch_results[1]\n",
    "        pred_loss += batch_results[2]\n",
    "        dis_loss += batch_results[3]\n",
    "        pred_count_joint += batch_results[4]\n",
    "        pred_count_class += batch_results[5]\n",
    "        dis_count += batch_results[6]\n",
    "        total += data[1].shape[0]     \n",
    "        \n",
    "    print(f\"test_loss={loss/total}, \"\n",
    "          f\"test_kl_loss={kl_loss/total}, \" \n",
    "          f\"test_pred_loss={pred_loss/total}, \"\n",
    "          f\"test_dis_loss={dis_loss/total}, \"\n",
    "          f\"test_joint_acc={pred_count_joint/total}, \"\n",
    "          f\"test_class_acc={pred_count_class/total}, \"\n",
    "          f\"test_dis_acc={dis_count/total}\"\n",
    "         )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DANN(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        classes=65\n",
    "    ):\n",
    "        super(DANN, self).__init__()\n",
    "        self.classes = classes\n",
    "        self.encoder = build_encoder()\n",
    "        self.classifier = build_classifier(512, self.classes, False)\n",
    "        self.discriminator = build_discriminator(512)\n",
    "    \n",
    "    def forward(self, inputs, rep_loss=1):\n",
    "        features = self.encoder(inputs)\n",
    "        classes = self.classifier(features)\n",
    "        domains = self.discriminator(ReverseLayer.apply(features, rep_loss))\n",
    "        return classes, domains\n",
    "    \n",
    "    def run_batch(self, imgs, labels=None, training=True, rep_loss=1):\n",
    "        if training:\n",
    "            opt = optim.Adam(self.parameters(), lr=1e-4)\n",
    "            opt.zero_grad()\n",
    "            \n",
    "        class_pred_loss = 0\n",
    "        pred_count_class = 0\n",
    "        \n",
    "        imgs = imgs.cuda()\n",
    "        y_pred, domain_pred_label = self(imgs) \n",
    "        \n",
    "        if labels is not None:\n",
    "            labels = labels.cuda()\n",
    "            labels = labels.to(dtype=torch.int64)\n",
    "            class_labels = labels[:,1]\n",
    "            domain_labels = torch.cat((labels[:,0], torch.ones(imgs.shape[0] - labels.shape[0], dtype=torch.long).cuda()), 0)\n",
    "\n",
    "            y_pred = y_pred[:labels.shape[0]]\n",
    "\n",
    "            class_pred_loss = torch.nn.NLLLoss()(torch.log(y_pred), class_labels)\n",
    "            pred_count_class = int(torch.count_nonzero(torch.argmax(y_pred, 1) == class_labels))\n",
    "             \n",
    "        dis_loss = torch.nn.NLLLoss()(torch.log(domain_pred_label), domain_labels) * rep_loss\n",
    "        dis_count = int(torch.count_nonzero(torch.argmax(domain_pred_label, 1) == domain_labels))\n",
    "        \n",
    "        loss = class_pred_loss + dis_loss\n",
    "\n",
    "        if training:\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        return (\n",
    "            float(loss),  \n",
    "            float(class_pred_loss), \n",
    "            float(dis_loss), \n",
    "            float(pred_count_class),\n",
    "            float(dis_count)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    }
   ],
   "source": [
    "dann = DANN(classes=len(d.classes))\n",
    "_ = dann.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "loss=0.029174270220899676, pred_loss=0.028099820627803692, dis_loss=0.00107444961125042, class_acc=0.36826347305389223, dis_acc=0.6510721247563352\n",
      "\n",
      "val_loss=0.05201121436225043, val_pred_loss=0.02787361145019531, val_dis_loss=0.02413760291205512, val_class_acc=0.4222222222222222, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.04142024642542789, test_pred_loss=0.02256692919814796, test_dis_loss=0.018853317227279932, test_class_acc=0.45614035087719296, test_dis_acc=0.0\n",
      "\n",
      "Epoch 2\n",
      "loss=0.03042834834513376, pred_loss=0.02361818038464522, dis_loss=0.006810167938703217, class_acc=0.5029940119760479, dis_acc=0.631578947368421\n",
      "\n",
      "val_loss=0.07134602864583334, val_pred_loss=0.026157898373074, val_dis_loss=0.04518813027275933, val_class_acc=0.4888888888888889, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.05892959812231231, test_pred_loss=0.023572536936977452, test_dis_loss=0.03535706118533486, test_class_acc=0.47368421052631576, test_dis_acc=0.0\n",
      "\n",
      "Epoch 3\n",
      "loss=0.030507138017092997, pred_loss=0.019705610317096375, dis_loss=0.010801528273676803, class_acc=0.5778443113772455, dis_acc=0.6335282651072125\n",
      "\n",
      "val_loss=0.09169868893093533, val_pred_loss=0.02997811900244819, val_dis_loss=0.06172056727939182, val_class_acc=0.4888888888888889, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.07411993595591762, test_pred_loss=0.025813784515648558, test_dis_loss=0.048306155623051156, test_class_acc=0.42105263157894735, test_dis_acc=0.0\n",
      "\n",
      "Epoch 4\n",
      "loss=0.03062821828831009, pred_loss=0.015921106928738004, dis_loss=0.014707111359572086, class_acc=0.6826347305389222, dis_acc=0.6198830409356725\n",
      "\n",
      "val_loss=0.09386359320746528, val_pred_loss=0.024239691098531087, val_dis_loss=0.06962390475802951, val_class_acc=0.5333333333333333, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.07852632957592345, test_pred_loss=0.02432436273809065, test_dis_loss=0.05420197102061489, test_class_acc=0.42105263157894735, test_dis_acc=0.0\n",
      "\n",
      "Epoch 5\n",
      "loss=0.02963799633245487, pred_loss=0.013052544572897125, dis_loss=0.016585451730510646, class_acc=0.7784431137724551, dis_acc=0.6198830409356725\n",
      "\n",
      "val_loss=0.10351280636257595, val_pred_loss=0.03195347256130642, val_dis_loss=0.07155933909946018, val_class_acc=0.4666666666666667, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.08659287502891139, test_pred_loss=0.031081689031500565, test_dis_loss=0.05551119018019291, test_class_acc=0.42105263157894735, test_dis_acc=0.0\n",
      "\n",
      "Epoch 6\n",
      "loss=0.027793641443605775, pred_loss=0.010001606876157646, dis_loss=0.017792034494830387, class_acc=0.8502994011976048, dis_acc=0.6081871345029239\n",
      "\n",
      "val_loss=0.1148018095228407, val_pred_loss=0.03831384711795383, val_dis_loss=0.07648795975579156, val_class_acc=0.4888888888888889, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.09781394088477419, test_pred_loss=0.03825421082346063, test_dis_loss=0.059559730061313564, test_class_acc=0.42105263157894735, test_dis_acc=0.0\n",
      "\n",
      "Epoch 7\n",
      "loss=0.027097977276666355, pred_loss=0.008508295285539088, dis_loss=0.018589681889462424, class_acc=0.8892215568862275, dis_acc=0.6335282651072125\n",
      "\n",
      "val_loss=0.11154002083672418, val_pred_loss=0.03790092998080784, val_dis_loss=0.07363909085591634, val_class_acc=0.4444444444444444, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.08402418671992787, test_pred_loss=0.025881123124507435, test_dis_loss=0.05814306359542044, test_class_acc=0.5789473684210527, test_dis_acc=0.0\n",
      "\n",
      "Epoch 8\n",
      "loss=0.02636782929562686, pred_loss=0.007281815041343139, dis_loss=0.019086014050954034, class_acc=0.9191616766467066, dis_acc=0.6374269005847953\n",
      "\n",
      "val_loss=0.09127944310506185, val_pred_loss=0.033178959952460396, val_dis_loss=0.058100483152601454, val_class_acc=0.6, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.09120459305612665, test_pred_loss=0.04516903977645071, test_dis_loss=0.046035553279675935, test_class_acc=0.3684210526315789, test_dis_acc=0.0\n",
      "\n",
      "Epoch 9\n",
      "loss=0.02384787577169913, pred_loss=0.007265386583744666, dis_loss=0.016582489449378342, class_acc=0.8952095808383234, dis_acc=0.631578947368421\n",
      "\n",
      "val_loss=0.10261319478352865, val_pred_loss=0.037215256690979005, val_dis_loss=0.06539794074164497, val_class_acc=0.5777777777777777, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.09208098629064727, test_pred_loss=0.04173614267717328, test_dis_loss=0.050344843613473994, test_class_acc=0.5087719298245614, test_dis_acc=0.0\n",
      "\n",
      "Epoch 10\n",
      "loss=0.020924443273748802, pred_loss=0.003817861656464099, dis_loss=0.017106581762520192, class_acc=0.9431137724550899, dis_acc=0.6374269005847953\n",
      "\n",
      "val_loss=0.10362114376491971, val_pred_loss=0.03728836907280816, val_dis_loss=0.06633277469211155, val_class_acc=0.6, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.09547330622087445, test_pred_loss=0.044118814301072506, test_dis_loss=0.051354491919801945, test_class_acc=0.543859649122807, test_dis_acc=0.0\n",
      "\n",
      "Epoch 11\n",
      "loss=0.020473568702069407, pred_loss=0.002236634325853333, dis_loss=0.018236934732043023, class_acc=0.9670658682634731, dis_acc=0.5984405458089669\n",
      "\n",
      "val_loss=0.12977623409695097, val_pred_loss=0.06469129986233181, val_dis_loss=0.06508492893642849, val_class_acc=0.4222222222222222, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.09383179848654229, test_pred_loss=0.04390435051499752, test_dis_loss=0.04992744797154477, test_class_acc=0.5087719298245614, test_dis_acc=0.0\n",
      "\n",
      "Epoch 12\n",
      "loss=0.022535823358197427, pred_loss=0.004166746802526376, dis_loss=0.018369076544778387, class_acc=0.9491017964071856, dis_acc=0.6237816764132553\n",
      "\n",
      "val_loss=0.11069405873616536, val_pred_loss=0.043495061662462024, val_dis_loss=0.0671989917755127, val_class_acc=0.5777777777777777, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.09418700034158271, test_pred_loss=0.04308794674120451, test_dis_loss=0.05109905778316029, test_class_acc=0.5614035087719298, test_dis_acc=0.0\n",
      "\n",
      "Epoch 13\n",
      "loss=0.02561873278887416, pred_loss=0.0057416357822556476, dis_loss=0.01987709685956758, class_acc=0.9311377245508982, dis_acc=0.6042884990253411\n",
      "\n",
      "val_loss=0.11016110314263237, val_pred_loss=0.051997301313612194, val_dis_loss=0.05816380182902018, val_class_acc=0.5333333333333333, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.09117242746185839, test_pred_loss=0.046542778349759284, test_dis_loss=0.044629649112099094, test_class_acc=0.5087719298245614, test_dis_acc=0.0\n",
      "\n",
      "Epoch 14\n",
      "loss=0.022688189677560075, pred_loss=0.005413307408942, dis_loss=0.017274882303111503, class_acc=0.9311377245508982, dis_acc=0.6062378167641326\n",
      "\n",
      "val_loss=0.10695059034559462, val_pred_loss=0.043007082409328885, val_dis_loss=0.06394350793626573, val_class_acc=0.6666666666666666, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.0964902074713456, test_pred_loss=0.04642300856740851, test_dis_loss=0.05006719890393709, test_class_acc=0.5614035087719298, test_dis_acc=0.0\n",
      "\n",
      "Epoch 15\n",
      "loss=0.023175807143280148, pred_loss=0.0043213268411554555, dis_loss=0.01885448036021889, class_acc=0.9461077844311377, dis_acc=0.6081871345029239\n",
      "\n",
      "val_loss=0.13141538831922744, val_pred_loss=0.06858803961012098, val_dis_loss=0.0628273540072971, val_class_acc=0.4888888888888889, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.10411178020008824, test_pred_loss=0.0554303579163133, test_dis_loss=0.04868142228377493, test_class_acc=0.5263157894736842, test_dis_acc=0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rep_loss=1\n",
    "\n",
    "for p in dann.parameters():\n",
    "    p.requires_grad = True    \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    \n",
    "    loss, pred_loss, dis_loss, nlab_total = (0,0,0,0) \n",
    "    pred_count_class, dis_count, lab_total = (0,0,0)\n",
    "    len_dataloader = max(len(train_label), len(train_nlabel))\n",
    "    \n",
    "    for i, (batch_label, batch_nlabel) in enumerate(itertools.zip_longest(train_label, train_nlabel)):\n",
    "        \n",
    "        p = float(i + epoch * len_dataloader) / epochs / len_dataloader\n",
    "        rep_loss=2. / (1. + np.exp(-10 * p)) - 1\n",
    "        \n",
    "        if batch_label is not None:\n",
    "            labels = batch_label[1]\n",
    "            \n",
    "            if batch_nlabel is not None:\n",
    "                imgs = torch.cat((batch_label[0], batch_nlabel), 0)\n",
    "            else:\n",
    "                imgs = batch_label[0]\n",
    "        else:\n",
    "            imgs = batch_nlabel\n",
    "            labels = None\n",
    "                \n",
    "        batch_results = dann.run_batch(imgs, labels, rep_loss=rep_loss)\n",
    "        loss += batch_results[0]\n",
    "        pred_loss += batch_results[1]\n",
    "        dis_loss += batch_results[2]\n",
    "        pred_count_class += batch_results[3]\n",
    "        dis_count += batch_results[4]\n",
    "        \n",
    "        if batch_label is not None:\n",
    "            lab_total += batch_label[1].shape[0]\n",
    "        if batch_nlabel is not None:\n",
    "            nlab_total += batch_nlabel.shape[0]\n",
    "    total = lab_total + nlab_total\n",
    "        \n",
    "    print(f\"loss={loss/total}, \"\n",
    "          f\"pred_loss={pred_loss/total}, \"\n",
    "          f\"dis_loss={dis_loss/total}, \"\n",
    "          f\"class_acc={pred_count_class/lab_total}, \"\n",
    "          f\"dis_acc={dis_count/total}\"\n",
    "         )\n",
    "    print()\n",
    "    \n",
    "    loss, pred_loss, dis_loss, total = (0,0,0,0) \n",
    "    pred_count_class, dis_count = (0,0)\n",
    "    \n",
    "    for data in val:    \n",
    "        imgs, labels = data   \n",
    "        batch_results = dann.run_batch(imgs, labels, training=False, rep_loss=rep_loss)\n",
    "        loss += batch_results[0]\n",
    "        pred_loss += batch_results[1]\n",
    "        dis_loss += batch_results[2]\n",
    "        pred_count_class += batch_results[3]\n",
    "        dis_count += batch_results[4]\n",
    "        total += data[1].shape[0]  \n",
    "            \n",
    "    print(f\"val_loss={loss/total}, \"\n",
    "          f\"val_pred_loss={pred_loss/total}, \"\n",
    "          f\"val_dis_loss={dis_loss/total}, \"\n",
    "          f\"val_class_acc={pred_count_class/total}, \"\n",
    "          f\"val_dis_acc={dis_count/total}\"\n",
    "         )\n",
    "    print()\n",
    "\n",
    "    \n",
    "    loss, pred_loss, dis_loss, total = (0,0,0,0) \n",
    "    pred_count_class, dis_count = (0,0)\n",
    "    for data in test:\n",
    "        imgs, labels = data\n",
    "        batch_results = dann.run_batch(imgs, labels, training=False, rep_loss=rep_loss)\n",
    "        loss += batch_results[0]\n",
    "        pred_loss += batch_results[1]\n",
    "        dis_loss += batch_results[2]\n",
    "        pred_count_class += batch_results[3]\n",
    "        dis_count += batch_results[4]\n",
    "        total += data[1].shape[0]       \n",
    "        \n",
    "    print(f\"test_loss={loss/total}, \"\n",
    "          f\"test_pred_loss={pred_loss/total}, \"\n",
    "          f\"test_dis_loss={dis_loss/total}, \"\n",
    "          f\"test_class_acc={pred_count_class/total}, \"\n",
    "          f\"test_dis_acc={dis_count/total}\"\n",
    "         )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.04912133802447403, test_kl_loss=0.0032100612134264225, test_pred_loss=0.023766850170336272, test_dis_loss=0.022144424287896407, test_joint_acc=0.17543859649122806, test_class_acc=0.24561403508771928, test_dis_acc=0.0\n"
     ]
    }
   ],
   "source": [
    "loss, kl_loss, pred_loss, dis_loss, total = (0,0,0,0,0) \n",
    "pred_count_joint, pred_count_class, dis_count = (0,0,0)\n",
    "for data in test:\n",
    "    batch_results = m.run_batch(data, training=False, use_KL=use_KL, rep_loss=rep_loss)\n",
    "    loss += batch_results[0]\n",
    "    kl_loss += batch_results[1]\n",
    "    pred_loss += batch_results[2]\n",
    "    dis_loss += batch_results[3]\n",
    "    pred_count_joint += batch_results[4]\n",
    "    pred_count_class += batch_results[5]\n",
    "    dis_count += batch_results[6]\n",
    "    total += data[1].shape[0]\n",
    "\n",
    "print(f\"test_loss={loss/total}, \"\n",
    "      f\"test_kl_loss={kl_loss/total}, \" \n",
    "      f\"test_pred_loss={pred_loss/total}, \"\n",
    "      f\"test_dis_loss={dis_loss/total}, \"\n",
    "      f\"test_joint_acc={pred_count_joint/total}, \"\n",
    "      f\"test_class_acc={pred_count_class/total}, \"\n",
    "      f\"test_dis_acc={dis_count/total}\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in test:\n",
    "    imgs, labels = data\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_label, batch_nlabel in itertools.zip_longest(train_label, train_nlabel):\n",
    "    imgs_label , labels = batch_label\n",
    "    imgs_nlabel = batch_nlabel\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2744, 0.2950, 0.2825, 0.3014, 0.2855, 0.2858, 0.2895, 0.2864, 0.2892,\n",
       "        0.2879, 0.2831, 0.2841, 0.2889, 0.2999, 0.2810, 0.2836, 0.2994, 0.2932,\n",
       "        0.2896, 0.2690, 0.2878, 0.2886, 0.2119, 0.2940, 0.2667, 0.2445, 0.2914,\n",
       "        0.2854, 0.2884, 0.2849, 0.2927, 0.2858], device='cuda:0',\n",
       "       grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, domain_pred = m(imgs_nlabel.cuda())\n",
    "domain_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([57])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(torch.sum(y_pred, 1), 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([57])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2., 3., 4., 4., 2., 2., 1., 3., 2., 4., 4., 2., 2., 2., 2., 2.,\n",
       "        1., 3., 2., 1., 3., 4., 1., 3., 4., 1., 4., 3., 2., 1., 3., 4., 4., 4.,\n",
       "        1., 3., 4., 3., 2., 3., 2., 2., 1., 3., 3., 3., 4., 1., 1., 1., 1., 4.,\n",
       "        4., 2., 4.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4386, device='cuda:0')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.count_nonzero(torch.argmax(torch.sum(y_pred, 1), 1) == labels[:,1].cuda()) / labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred[:1]\n",
    "y_joint = torch.reshape(y_pred, (1, 2*4))\n",
    "    \n",
    "y_class = torch.unsqueeze(torch.sum(y_pred, 1), 1)\n",
    "y_domain = torch.unsqueeze(torch.sum(y_pred, 2), -1)\n",
    "    \n",
    "    \n",
    "y_ind_joint = torch.reshape((y_domain * y_class), (1,2*4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2102, 0.3443, 0.0579, 0.0241],\n",
       "         [0.0946, 0.2194, 0.0309, 0.0186]]], device='cuda:0',\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2102, 0.3443, 0.0579, 0.0241, 0.0946, 0.2194, 0.0309, 0.0186]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3048, 0.5637, 0.0888, 0.0427]]], device='cuda:0',\n",
       "       grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6365],\n",
       "         [0.3635]]], device='cuda:0', grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1940, 0.3588, 0.0565, 0.0272, 0.1108, 0.2049, 0.0323, 0.0155]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ind_joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(inf)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.KLDivLoss(log_target=True, reduction=\"sum\")(\n",
    "    torch.log(y_joint), \n",
    "    torch.log(y_ind_joint)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence(p, q):\n",
    "    p = p.reshape(-1)\n",
    "    q = q.reshape(-1)\n",
    "    print(p, q)\n",
    "    return sum(p[i] * torch.log2(p[i]/q[i]) for i in range(len(p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2102, 0.3443, 0.0579, 0.0241, 0.0946, 0.2194, 0.0309, 0.0186],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>) tensor([0.1940, 0.3588, 0.0565, 0.0272, 0.1108, 0.2049, 0.0323, 0.0155],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0046, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_divergence(y_joint, y_ind_joint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
