{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Function\n",
    "from torchsummary import summary\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ReverseLayer(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output = grad_output.neg() * ctx.alpha\n",
    "\n",
    "        return output, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder():\n",
    "    model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet34')\n",
    "    modules = list(model.children())[:-1] + [torch.nn.Flatten()]\n",
    "    model = nn.Sequential(*modules)\n",
    "    return model\n",
    "\n",
    "def build_classifier(input_shape, classes, joint=True):\n",
    "    domains = 2 if joint else 1\n",
    "    \n",
    "    classifier = nn.Sequential(\n",
    "        nn.Linear(input_shape, 1280),\n",
    "        nn.ReLU(True),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(1280, 1280),\n",
    "        nn.ReLU(True),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(1280, domains*classes),\n",
    "        nn.Softmax()\n",
    "    )\n",
    "    return classifier\n",
    "\n",
    "def build_discriminator(input_shape):\n",
    "    discriminator = nn.Sequential(\n",
    "        nn.Linear(input_shape, 1280),\n",
    "        nn.ReLU(True),\n",
    "        nn.Linear(1280, 1280),\n",
    "        nn.ReLU(True),\n",
    "        nn.Linear(1280, 2),\n",
    "        nn.Softmax()\n",
    "    )\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, labels=True):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        return x if self.labels else x[0]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(\n",
    "        self, \n",
    "        source_domain,\n",
    "        target_domain,\n",
    "        val_split=0.2,\n",
    "        test_split=0.2,\n",
    "        input_shape=(224,224),\n",
    "        target_labels=0.1,\n",
    "        target_train=False\n",
    "    ):\n",
    "        src_train, src_val = self.__prepare_data(\n",
    "            source_domain, \n",
    "            input_shape,\n",
    "            True, \n",
    "            val_split,\n",
    "            test_split,\n",
    "            target_labels\n",
    "        )\n",
    "              \n",
    "        train_label, train_nlabel, tar_val, test = self.__prepare_data(\n",
    "            target_domain,  \n",
    "            input_shape, \n",
    "            False, \n",
    "            val_split,\n",
    "            test_split,\n",
    "            target_labels\n",
    "        )\n",
    "        \n",
    "        val = torch.utils.data.ConcatDataset([src_val, tar_val])\n",
    "        \n",
    "        if target_train:\n",
    "            train_label_set = train_label\n",
    "        else:\n",
    "            train_label_set = torch.utils.data.ConcatDataset([src_train, train_label])\n",
    "\n",
    "        self.train_label_loader = DataLoader(dataset=train_label_set, batch_size=32, shuffle=True, num_workers=0)\n",
    "        if target_labels < 1:\n",
    "            self.train_nlabel_loader = DataLoader(dataset=train_nlabel, batch_size=32, shuffle=True, num_workers=0)\n",
    "        else:\n",
    "            self.train_nlabel_loader = None\n",
    "        self.val_loader = DataLoader(dataset=val, batch_size=64, shuffle=True, num_workers=0)\n",
    "        self.test_loader = DataLoader(dataset=test, batch_size=64, shuffle=True, num_workers=0)\n",
    "    \n",
    "    def __prepare_data(self, folder, input_shape, src=True, val_split=0, test_split=0, target_labels=0.1):\n",
    "        \n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(input_shape),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        \n",
    "        label = 0 if src else 1\n",
    "        \n",
    "        data = torchvision.datasets.ImageFolder(folder, transform=transform)\n",
    "        data.target_transform = lambda id: torch.Tensor((label, id))\n",
    "        \n",
    "        self.classes = data.classes\n",
    "        \n",
    "        if src:\n",
    "            \n",
    "            if target_labels == 0:\n",
    "                train, val = torch.utils.data.random_split(\n",
    "                    data, \n",
    "                    [round(len(data)*(1-val_split) - 1e-5), round(len(data)*val_split + 1e-5)]\n",
    "                ) \n",
    "            else:\n",
    "                train, val = torch.utils.data.random_split(\n",
    "                    data, \n",
    "                    [len(data), 0]\n",
    "                )  \n",
    "            \n",
    "            return train, val\n",
    "        \n",
    "        else:\n",
    "            data, test = torch.utils.data.random_split(\n",
    "                data, \n",
    "                [round(len(data)*(1-test_split) - 1e-5), round(len(data)*test_split + 1e-5)]\n",
    "            )\n",
    "        \n",
    "            train, train_nlabel = torch.utils.data.random_split(\n",
    "                data, \n",
    "                [round(len(data)*target_labels - 1e-5), round(len(data)*(1-target_labels) + 1e-5)]\n",
    "            ) \n",
    "    \n",
    "            train_label, val = torch.utils.data.random_split(\n",
    "                train, \n",
    "                [round(len(train)*(1-val_split) - 1e-5), round(len(train)*val_split + 1e-5)]\n",
    "            )\n",
    "            \n",
    "            return train_label, Dataset(train_nlabel, False), val, test\n",
    "        \n",
    "    def train_data(self):\n",
    "        return self.train_label_loader, self.train_nlabel_loader\n",
    "    \n",
    "    def val_data(self):\n",
    "        return self.val_loader\n",
    "    \n",
    "    def test_data(self):\n",
    "        return self.test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_Loss(y_pred, classes):\n",
    "    y_joint = torch.reshape(y_pred, (-1, 2*classes))\n",
    "    \n",
    "    y_class = torch.unsqueeze(torch.sum(y_pred, 1), 1)\n",
    "    y_domain = torch.unsqueeze(torch.sum(y_pred, 2), -1)\n",
    "    \n",
    "    \n",
    "    y_ind_joint = torch.reshape((y_domain * y_class), (-1,2*classes))\n",
    "    \n",
    "    return torch.nn.KLDivLoss(log_target=True, reduction=\"sum\")(\n",
    "        torch.log(y_joint), \n",
    "        torch.log(y_ind_joint)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DANNModel(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        classes=65,\n",
    "    ):\n",
    "        super(SingleDomainModel, self).__init__()\n",
    "        self.classes = classes\n",
    "        self.encoder = build_encoder()\n",
    "        self.classifier = build_classifier(512, self.classes)\n",
    "        self.discriminator = build_discriminator(512)\n",
    "    \n",
    "    def forward(self, inputs, rep_loss):\n",
    "        features = self.encoder(inputs)\n",
    "        classes = self.classifier(features)\n",
    "        classes = torch.reshape(classes, (-1, 2, self.classes))\n",
    "        domains = self.discriminator(ReverseLayer.apply(features, rep_loss))\n",
    "        return classes, domains\n",
    "    \n",
    "    def run_batch(self, imgs, labels=None, training=True, use_KL=True, rep_loss=1, risk_loss=1):\n",
    "        if training:\n",
    "            opt = optim.Adam(self.parameters(), lr=1e-4)\n",
    "#             opt = torch.optim.SGD(m.parameters(), lr=1e-4, momentum=0.9, weight_decay=5e-4)\n",
    "            opt.zero_grad()\n",
    "            \n",
    "        kl_loss = 0\n",
    "        class_pred_loss = 0\n",
    "        pred_count_joint = 0\n",
    "        pred_count_class = 0\n",
    "        \n",
    "        imgs = imgs.cuda()\n",
    "        y_pred, domain_pred_label = self(imgs, rep_loss) \n",
    "        \n",
    "        if labels is not None:\n",
    "            labels = labels.cuda()\n",
    "            labels = labels.to(dtype=torch.int64)\n",
    "            joint_labels = labels[:,0] * m.classes + labels[:,1]\n",
    "            dom_labels = torch.cat((labels[:,0], torch.ones(imgs.shape[0] - labels.shape[0], dtype=torch.long).cuda()), 0)\n",
    "\n",
    "            y_pred = y_pred[:labels.shape[0]]\n",
    "            y_joint = torch.reshape(y_pred, (-1,2*m.classes))\n",
    "            y_class = torch.sum(y_pred, 1)\n",
    "\n",
    "            if use_KL:\n",
    "                kl_loss = KL_Loss(y_pred, m.classes) * risk_loss\n",
    "\n",
    "            class_pred_loss = torch.nn.NLLLoss()(torch.log(y_class), labels[:,1])\n",
    "            \n",
    "            pred_count_joint = torch.count_nonzero(torch.argmax(y_joint, 1) == joint_labels)\n",
    "            pred_count_class = torch.count_nonzero(torch.argmax(y_class, 1) == labels[:,1])\n",
    "             \n",
    "        dis_loss = torch.nn.NLLLoss()(torch.log(domain_pred_label), dom_labels)\n",
    "        dis_count = torch.count_nonzero(torch.argmax(domain_pred_label, 1) == dom_labels)\n",
    "        \n",
    "        loss = class_pred_loss + kl_loss + dis_loss\n",
    "\n",
    "        if training:\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        return (\n",
    "            float(loss), \n",
    "            float(kl_loss), \n",
    "            float(class_pred_loss), \n",
    "            float(dis_loss), \n",
    "            float(pred_count_joint), \n",
    "            float(pred_count_class),\n",
    "            float(dis_count)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleDomainModel(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        classes=65,\n",
    "        use_KL=True,\n",
    "        risk_lambda=1,\n",
    "        lr=1e-4\n",
    "    ):\n",
    "        super(SingleDomainModel, self).__init__()\n",
    "        self.classes = classes\n",
    "        self.encoder = build_encoder()\n",
    "        self.classifier = build_classifier(512, self.classes, use_KL)\n",
    "        \n",
    "        self.lr = lr\n",
    "        \n",
    "        self.use_KL = use_KL\n",
    "        self.risk_lambda = risk_lambda\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        features = self.encoder(inputs)\n",
    "        classes = self.classifier(features)\n",
    "        if self.use_KL:\n",
    "            classes = torch.reshape(classes, (-1, 2, self.classes))\n",
    "        return classes\n",
    "    \n",
    "    def __print_metrics(self, metrics, prefix=\"\", precision=4, space=1):\n",
    "        for k, v in metrics.items():\n",
    "            print(prefix + k, round(v, precision), sep=\": \", end=' ')\n",
    "        for i in range(space):\n",
    "            print()\n",
    "    \n",
    "    def __train_encoder(self, imgs, labels):\n",
    "        encoder_opt = optim.Adam(self.encoder.parameters(), lr=self.lr)\n",
    "        encoder_opt.zero_grad()\n",
    "        \n",
    "        # Feedforward\n",
    "        y_pred = self(imgs) \n",
    "        y_class = torch.sum(y_pred, 1)\n",
    "        \n",
    "        # Calculate losses and metrics\n",
    "        class_pred_loss = torch.nn.NLLLoss()(torch.log(y_class), labels)\n",
    "        kl_loss = KL_Loss(y_pred, m.classes) * self.risk_lambda\n",
    "        encoder_loss = class_pred_loss + kl_loss\n",
    "        \n",
    "        # Backpropogation\n",
    "        encoder_loss.backward()\n",
    "        encoder_opt.step()\n",
    "        \n",
    "        return y_class, float(encoder_loss), float(kl_loss)\n",
    "            \n",
    "    def __train_classifier(self, imgs, labels):\n",
    "        classifier_opt = optim.Adam(self.encoder.parameters(), lr=self.lr)\n",
    "        classifier_opt.zero_grad()\n",
    "        \n",
    "        # Feedforward\n",
    "        y_pred = self(imgs) \n",
    "        y_joint = torch.reshape(y_pred, (-1,2*m.classes))          \n",
    "\n",
    "        # Calculate losses and metrics\n",
    "        joint_pred_loss = torch.nn.NLLLoss()(torch.log(y_joint), labels)\n",
    "        classifier_loss = joint_pred_loss\n",
    "        \n",
    "        # Backpropogation\n",
    "        classifier_loss.backward()\n",
    "        classifier_opt.step()\n",
    "        \n",
    "        return y_pred, float(classifier_loss)\n",
    "    \n",
    "    def __full_training(self, imgs, labels):\n",
    "        opt = optim.Adam(self.parameters(), lr=self.lr)\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        # Feedforward\n",
    "        y_pred = self(imgs) \n",
    "        \n",
    "        # Calculate losses and metrics\n",
    "        class_pred_loss = torch.nn.NLLLoss()(torch.log(y_pred), labels)\n",
    "        loss = class_pred_loss\n",
    "        \n",
    "        # Backpropogation\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        return y_pred, float(loss)\n",
    "    \n",
    "    def __train_batch(self, imgs, labels):\n",
    "        \n",
    "        imgs = imgs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        labels = labels.to(dtype=torch.int64)\n",
    "        class_labels = labels[:,1]\n",
    "        joint_labels = labels[:,0] * m.classes + labels[:,1]\n",
    "        \n",
    "        if self.use_KL:\n",
    "            # Two step training of encoder and classifier with KL-loss\n",
    "            _, encoder_loss, kl_loss = self.__train_encoder(imgs, class_labels)\n",
    "            y_pred, classifier_loss = self.__train_classifier(imgs, joint_labels)\n",
    "            \n",
    "            y_class = torch.sum(y_pred, 1)\n",
    "            y_joint = torch.reshape(y_pred, (-1,2*m.classes))\n",
    "            \n",
    "            pred_class_count = torch.count_nonzero(torch.argmax(y_class, 1) == class_labels)\n",
    "            pred_joint_count = torch.count_nonzero(torch.argmax(y_joint, 1) == joint_labels)\n",
    "            \n",
    "            loss_metrics = {\n",
    "                \"loss\": encoder_loss + classifier_loss,\n",
    "                \"encoder_loss\": encoder_loss,\n",
    "                \"kl_loss\": kl_loss,\n",
    "                \"classifier_loss\": classifier_loss\n",
    "            }\n",
    "            \n",
    "            acc_metrics = {\n",
    "                \"joint_acc\": float(pred_joint_count),\n",
    "                \"class_acc\": float(pred_class_count)\n",
    "            }\n",
    "            \n",
    "        else:\n",
    "            y_pred, loss = self.__full_training(imgs, class_labels)\n",
    "            \n",
    "            pred_class_count = torch.count_nonzero(torch.argmax(y_pred, 1) == class_labels)\n",
    "            \n",
    "            loss_metrics = {\n",
    "                \"loss\": loss\n",
    "            }\n",
    "            \n",
    "            acc_metrics = {\n",
    "                \"class_acc\": float(pred_class_count)\n",
    "            }\n",
    "\n",
    "        return loss_metrics, acc_metrics\n",
    "    \n",
    "    def train(self, epochs, train_loader, val_loader=None, patience=None):\n",
    "        \n",
    "        train_size = len(train_loader.dataset)\n",
    "        min_val_loss = np.inf\n",
    "        best_model = None\n",
    "        \n",
    "        current_patience = patience\n",
    "        \n",
    "        # Perform training over number of epochs\n",
    "        for i in range(epochs):\n",
    "            print(f\"Epoch {i+1}\")\n",
    "            \n",
    "            loss_metrics = defaultdict(float)\n",
    "            acc_metrics = defaultdict(float)\n",
    "            \n",
    "            for imgs, labels in train_loader:\n",
    "                batch_loss, batch_acc = self.__train_batch(imgs, labels)\n",
    "\n",
    "                for k, v in batch_loss.items():\n",
    "                    loss_metrics[k] += v / train_size\n",
    "                for k, v in batch_acc.items():\n",
    "                    acc_metrics[k] += v / train_size\n",
    "            \n",
    "            self.__print_metrics(loss_metrics, precision=6)\n",
    "            self.__print_metrics(acc_metrics, precision=4, space=2)\n",
    "            \n",
    "            # Run on validation set if provided\n",
    "            if val_loader is not None:\n",
    "                val_size = len(val_loader.dataset)\n",
    "                loss_metrics, acc_metrics = self.evaluate(val_loader, val=True)\n",
    "                \n",
    "                # Early stopping\n",
    "                if loss_metrics[\"loss\"] < min_val_loss:\n",
    "                    min_val_loss = loss_metrics[\"loss\"]\n",
    "                    best_model = copy.deepcopy(self.state_dict())\n",
    "                    current_patience = patience\n",
    "                else:\n",
    "                    if current_patience is not None:\n",
    "                        current_patience -= 1\n",
    "                        if current_patience <= 0:\n",
    "                            break\n",
    "                        \n",
    "        self.load_state_dict(best_model)\n",
    "    \n",
    "    def evaluate(self, loader, val=False):\n",
    "        \n",
    "        data_size = len(loader.dataset)\n",
    "        loss_metrics = defaultdict(float)\n",
    "        acc_metrics = defaultdict(float)\n",
    "        \n",
    "        for imgs, labels in loader:\n",
    "            batch_loss, batch_acc = self.__evaluate_batch(imgs, labels)\n",
    "            \n",
    "            for k, v in batch_loss.items():\n",
    "                loss_metrics[k] += v / data_size\n",
    "            for k, v in batch_acc.items():\n",
    "                acc_metrics[k] += v / data_size\n",
    "                \n",
    "        prefix = \"val_\" if val else \"\"\n",
    "        \n",
    "        self.__print_metrics(loss_metrics, prefix=prefix, precision=6)\n",
    "        self.__print_metrics(acc_metrics, prefix=prefix, precision=4, space=2)\n",
    "                \n",
    "        return loss_metrics, acc_metrics\n",
    "            \n",
    "    def __evaluate_batch(self, imgs, labels):\n",
    "        imgs = imgs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        labels = labels.to(dtype=torch.int64)\n",
    "        class_labels = labels[:,1]\n",
    "        joint_labels = labels[:,0] * m.classes + labels[:,1]\n",
    "        \n",
    "        # Feedforward\n",
    "        y_pred = self(imgs)\n",
    "        \n",
    "        if self.use_KL:           \n",
    "            y_class = torch.sum(y_pred, 1)\n",
    "            y_joint = torch.reshape(y_pred, (-1,2*m.classes))\n",
    "            \n",
    "            class_pred_loss = float(torch.nn.NLLLoss()(torch.log(y_class), class_labels))\n",
    "            joint_pred_loss = float(torch.nn.NLLLoss()(torch.log(y_joint), joint_labels))\n",
    "            kl_loss = float(KL_Loss(y_pred, m.classes) * self.risk_lambda)\n",
    "            \n",
    "            encoder_loss = class_pred_loss + kl_loss\n",
    "            \n",
    "            pred_class_count = torch.count_nonzero(torch.argmax(y_class, 1) == class_labels)\n",
    "            \n",
    "            loss_metrics = {\n",
    "                \"loss\": encoder_loss,\n",
    "                \"kl_loss\": kl_loss,\n",
    "                \"classifier_loss\": class_pred_loss\n",
    "            }\n",
    "            \n",
    "            acc_metrics = {\n",
    "                \"class_acc\": float(pred_class_count)\n",
    "            }\n",
    "            \n",
    "        else:          \n",
    "            pred_class_count = torch.count_nonzero(torch.argmax(y_pred, 1) == class_labels)\n",
    "            loss = float(torch.nn.NLLLoss()(torch.log(y_pred), class_labels))\n",
    "            \n",
    "            loss_metrics = {\n",
    "                \"loss\": loss\n",
    "            }\n",
    "            \n",
    "            acc_metrics = {\n",
    "                \"class_acc\": float(pred_class_count)\n",
    "            }\n",
    "\n",
    "        return loss_metrics, acc_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-196-e69259a73f44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtarget_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Product\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m d = DataGenerator(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0msource_domain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtarget_domain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-187-c3f0afb439c2>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source_domain, target_domain, val_split, test_split, input_shape, target_labels, target_train)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_nlabel_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers)\u001b[0m\n\u001b[1;32m    260\u001b[0m                     \u001b[0;31m# Cannot statically verify that dataset is Sized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                     \u001b[0;31m# Somewhat related: see NOTE [ Lack of Default `__len__` in Python Abstract Base Classes ]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             raise ValueError(\"num_samples should be a positive integer \"\n\u001b[0m\u001b[1;32m    104\u001b[0m                              \"value, but got num_samples={}\".format(self.num_samples))\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "data_folder = \"../Datasets/Experiment\"\n",
    "src_folder = os.path.join(data_folder, \"Real World\")\n",
    "target_folder = os.path.join(data_folder, \"Product\")\n",
    "\n",
    "d = DataGenerator(\n",
    "    source_domain=src_folder,\n",
    "    target_domain=target_folder,\n",
    "    val_split=0.2,\n",
    "    test_split=0.2,\n",
    "    input_shape=(224,224),\n",
    "    target_labels=0.01,\n",
    "    target_train=False\n",
    ")\n",
    "\n",
    "train_label, train_nlabel = d.train_data()\n",
    "val = d.val_data()\n",
    "test = d.test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 2.],\n",
       "        [1., 0.],\n",
       "        [1., 2.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 2.],\n",
       "        [1., 1.],\n",
       "        [1., 3.],\n",
       "        [1., 1.],\n",
       "        [1., 2.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 2.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 2.],\n",
       "        [1., 3.],\n",
       "        [1., 3.],\n",
       "        [1., 1.],\n",
       "        [1., 3.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 2.],\n",
       "        [1., 3.],\n",
       "        [1., 2.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 2.],\n",
       "        [1., 1.],\n",
       "        [1., 2.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 3.],\n",
       "        [1., 0.],\n",
       "        [1., 2.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = iter(val).next()\n",
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    }
   ],
   "source": [
    "m = SingleDomainModel(classes=len(d.classes), use_KL=False, risk_lambda=10, lr=1e-4)\n",
    "_ = m.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "loss: 0.044896 \n",
      "class_acc: 0.2762 \n",
      "\n",
      "val_loss: 0.026791 \n",
      "val_class_acc: 0.5111 \n",
      "\n",
      "Epoch 2\n",
      "loss: 0.039572 \n",
      "class_acc: 0.453 \n",
      "\n",
      "val_loss: 0.023938 \n",
      "val_class_acc: 0.4444 \n",
      "\n",
      "Epoch 3\n",
      "loss: 0.033005 \n",
      "class_acc: 0.5912 \n",
      "\n",
      "val_loss: 0.020886 \n",
      "val_class_acc: 0.6444 \n",
      "\n",
      "Epoch 4\n",
      "loss: 0.022824 \n",
      "class_acc: 0.7956 \n",
      "\n",
      "val_loss: 0.016919 \n",
      "val_class_acc: 0.7556 \n",
      "\n",
      "Epoch 5\n",
      "loss: 0.013666 \n",
      "class_acc: 0.9006 \n",
      "\n",
      "val_loss: 0.01712 \n",
      "val_class_acc: 0.6889 \n",
      "\n",
      "Epoch 6\n",
      "loss: 0.008326 \n",
      "class_acc: 0.9337 \n",
      "\n",
      "val_loss: 0.010537 \n",
      "val_class_acc: 0.8444 \n",
      "\n",
      "Epoch 7\n",
      "loss: 0.007756 \n",
      "class_acc: 0.9392 \n",
      "\n",
      "val_loss: 0.011855 \n",
      "val_class_acc: 0.8222 \n",
      "\n",
      "Epoch 8\n",
      "loss: 0.003516 \n",
      "class_acc: 0.9724 \n",
      "\n",
      "val_loss: 0.012149 \n",
      "val_class_acc: 0.8222 \n",
      "\n",
      "Epoch 9\n",
      "loss: 0.005581 \n",
      "class_acc: 0.9337 \n",
      "\n",
      "val_loss: 0.00993 \n",
      "val_class_acc: 0.8667 \n",
      "\n",
      "Epoch 10\n",
      "loss: 0.002833 \n",
      "class_acc: 0.9669 \n",
      "\n",
      "val_loss: 0.018973 \n",
      "val_class_acc: 0.8 \n",
      "\n",
      "Epoch 11\n",
      "loss: 0.002869 \n",
      "class_acc: 0.989 \n",
      "\n",
      "val_loss: 0.028355 \n",
      "val_class_acc: 0.7556 \n",
      "\n",
      "Epoch 12\n",
      "loss: 0.003436 \n",
      "class_acc: 0.9669 \n",
      "\n",
      "val_loss: 0.022901 \n",
      "val_class_acc: 0.8444 \n",
      "\n",
      "Epoch 13\n",
      "loss: 0.001228 \n",
      "class_acc: 0.9945 \n",
      "\n",
      "val_loss: 0.024565 \n",
      "val_class_acc: 0.8444 \n",
      "\n",
      "Epoch 14\n",
      "loss: 0.00103 \n",
      "class_acc: 0.989 \n",
      "\n",
      "val_loss: 0.031307 \n",
      "val_class_acc: 0.8 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "m.train(100, train_label, val, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.011627 \n",
      "class_acc: 0.8246 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(defaultdict(float, {'loss': 0.01162700799473545}),\n",
       " defaultdict(float, {'class_acc': 0.8245614035087719}))"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "loss=0.0448097315912823, kl_loss=0.0031949610505652474, pred_loss=0.029040276423299986, dis_loss=0.012574494669311926, joint_acc=0.21428571428571427, class_acc=0.37714285714285717, dis_acc=0.5984405458089669\n",
      "\n",
      "val_loss=0.08116570048862033, val_kl_loss=0.0034040855036841498, val_pred_loss=0.030469600359598795, val_dis_loss=0.04729201528761122, val_joint_acc=0.044444444444444446, val_class_acc=0.28888888888888886, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.0665176458526076, test_kl_loss=0.004598480044749745, test_pred_loss=0.02362041515216493, test_dis_loss=0.03829875326993173, test_joint_acc=0.03508771929824561, test_class_acc=0.40350877192982454, test_dis_acc=0.0\n",
      "\n",
      "Epoch 2\n",
      "loss=0.046705354026883666, kl_loss=0.002489541328673707, pred_loss=0.028486819527534946, dis_loss=0.015728992328309176, joint_acc=0.22285714285714286, class_acc=0.3657142857142857, dis_acc=0.5458089668615984\n",
      "\n",
      "val_loss=0.0897398206922743, val_kl_loss=0.005053795377413432, val_pred_loss=0.02954330179426405, val_dis_loss=0.05514272583855523, val_joint_acc=0.17777777777777778, val_class_acc=0.35555555555555557, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.0712764723259106, test_kl_loss=0.0037328224433095833, test_pred_loss=0.023306045615882204, test_dis_loss=0.04423760531241434, test_joint_acc=0.2807017543859649, test_class_acc=0.3684210526315789, test_dis_acc=0.0\n",
      "\n",
      "Epoch 3\n",
      "loss=0.048656032099361306, kl_loss=0.0022763815830093145, pred_loss=0.027418718003390127, dis_loss=0.018960932135349592, joint_acc=0.2914285714285714, class_acc=0.4685714285714286, dis_acc=0.6296296296296297\n",
      "\n",
      "val_loss=0.07420233090718588, val_kl_loss=0.0015501073665089076, val_pred_loss=0.02914564079708523, val_dis_loss=0.04350658257802328, val_joint_acc=0.022222222222222223, val_class_acc=0.26666666666666666, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.06069182513052957, test_kl_loss=0.002316343156914962, test_pred_loss=0.02219285253892865, test_dis_loss=0.036182629434685955, test_joint_acc=0.0, test_class_acc=0.45614035087719296, test_dis_acc=0.0\n",
      "\n",
      "Epoch 4\n",
      "loss=0.0434258509332906, kl_loss=0.0018913252006845865, pred_loss=0.024550543542493853, dis_loss=0.016983982299038775, joint_acc=0.42857142857142855, class_acc=0.5428571428571428, dis_acc=0.6198830409356725\n",
      "\n",
      "val_loss=0.07541827095879448, val_kl_loss=0.002088767621252272, val_pred_loss=0.02545179261101617, val_dis_loss=0.04787771436903212, val_joint_acc=0.24444444444444444, val_class_acc=0.4888888888888889, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.06007429591396399, test_kl_loss=0.002007199353293369, test_pred_loss=0.018514505603857208, test_dis_loss=0.039552588211862666, test_joint_acc=0.14035087719298245, test_class_acc=0.631578947368421, test_dis_acc=0.0\n",
      "\n",
      "Epoch 5\n",
      "loss=0.040247909971612705, kl_loss=0.001809024671364946, pred_loss=0.021667219625811363, dis_loss=0.0167716642220815, joint_acc=0.5142857142857142, class_acc=0.5857142857142857, dis_acc=0.6042884990253411\n",
      "\n",
      "val_loss=0.0850806819068061, val_kl_loss=0.0020191659530003864, val_pred_loss=0.028407213422987194, val_dis_loss=0.054654301537407766, val_joint_acc=0.0, val_class_acc=0.4222222222222222, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.06465114626968116, test_kl_loss=0.002332663849780434, test_pred_loss=0.017793084445752595, test_dis_loss=0.04452539745130037, test_joint_acc=0.017543859649122806, test_class_acc=0.5789473684210527, test_dis_acc=0.0\n",
      "\n",
      "Epoch 6\n",
      "loss=0.037661203166894745, kl_loss=0.0013843670806921945, pred_loss=0.0187097486929122, dis_loss=0.017567087451384546, joint_acc=0.6057142857142858, class_acc=0.6685714285714286, dis_acc=0.5886939571150097\n",
      "\n",
      "val_loss=0.06816716723971897, val_kl_loss=0.001136200295554267, val_pred_loss=0.02545767625172933, val_dis_loss=0.041573291354709205, val_joint_acc=0.0, val_class_acc=0.4888888888888889, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.0525870072214227, test_kl_loss=0.001355193163219251, test_pred_loss=0.016837631401262786, test_dis_loss=0.0343941847483317, test_joint_acc=0.017543859649122806, test_class_acc=0.631578947368421, test_dis_acc=0.0\n",
      "\n",
      "Epoch 7\n",
      "loss=0.03329771606080946, kl_loss=0.0012013681058646642, pred_loss=0.016667807776096038, dis_loss=0.01542854001182794, joint_acc=0.64, class_acc=0.6971428571428572, dis_acc=0.594541910331384\n",
      "\n",
      "val_loss=0.07660190794203016, val_kl_loss=0.0012609745065371195, val_pred_loss=0.02525286144680447, val_dis_loss=0.05008807182312012, val_joint_acc=0.0, val_class_acc=0.5111111111111111, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.06014289772301389, test_kl_loss=0.0014261080507646526, test_pred_loss=0.01686186016651622, test_dis_loss=0.041854929505733024, test_joint_acc=0.0, test_class_acc=0.6842105263157895, test_dis_acc=0.0\n",
      "\n",
      "Epoch 8\n",
      "loss=0.033196084215859456, kl_loss=0.0009850375644760987, pred_loss=0.015402074329569557, dis_loss=0.016808971791704264, joint_acc=0.7085714285714285, class_acc=0.7542857142857143, dis_acc=0.5847953216374269\n",
      "\n",
      "val_loss=0.07973314921061198, val_kl_loss=0.0014683052897453309, val_pred_loss=0.028694860140482583, val_dis_loss=0.04956998295254177, val_joint_acc=0.0, val_class_acc=0.5333333333333333, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.06164452904149106, test_kl_loss=0.0020759748785119307, test_pred_loss=0.01904078115496719, test_dis_loss=0.04052777039377313, test_joint_acc=0.0, test_class_acc=0.5789473684210527, test_dis_acc=0.0\n",
      "\n",
      "Epoch 9\n",
      "loss=0.028334730317485728, kl_loss=0.0010738557397041173, pred_loss=0.012251448561573586, dis_loss=0.015009425740260594, joint_acc=0.7457142857142857, class_acc=0.7857142857142857, dis_acc=0.6003898635477583\n",
      "\n",
      "val_loss=0.11072650485568576, val_kl_loss=0.0018668350246217515, val_pred_loss=0.03665362728966607, val_dis_loss=0.07220603624979655, val_joint_acc=0.0, val_class_acc=0.4888888888888889, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.07980321582994963, test_kl_loss=0.0016129147588161, test_pred_loss=0.019651157814159728, test_dis_loss=0.05853914377982156, test_joint_acc=0.0, test_class_acc=0.6666666666666666, test_dis_acc=0.0\n",
      "\n",
      "Epoch 10\n",
      "loss=0.029754595217416625, kl_loss=0.000896470508670714, pred_loss=0.00985821785285459, dis_loss=0.01899990706648278, joint_acc=0.7828571428571428, class_acc=0.8228571428571428, dis_acc=0.6393762183235867\n",
      "\n",
      "val_loss=0.07592148251003689, val_kl_loss=0.0008917099899715847, val_pred_loss=0.029050050841437445, val_dis_loss=0.04597972234090169, val_joint_acc=0.0, val_class_acc=0.5333333333333333, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.05964988156368858, test_kl_loss=0.0010141021849816305, test_pred_loss=0.020596550222028765, test_dis_loss=0.038039228372406544, test_joint_acc=0.0, test_class_acc=0.6491228070175439, test_dis_acc=0.0\n",
      "\n",
      "Epoch 11\n",
      "loss=0.022899388686025816, kl_loss=0.0004781368869351365, pred_loss=0.007527373135670816, dis_loss=0.01489387862166466, joint_acc=0.8171428571428572, class_acc=0.8571428571428571, dis_acc=0.5925925925925926\n",
      "\n",
      "val_loss=0.09254517025417752, val_kl_loss=0.0006386371536387337, val_pred_loss=0.03393683433532715, val_dis_loss=0.05796970261467828, val_joint_acc=0.0, val_class_acc=0.5555555555555556, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.07798187356246145, test_kl_loss=0.0009637916166531412, test_pred_loss=0.029617698569046825, test_dis_loss=0.047400382527133876, test_joint_acc=0.0, test_class_acc=0.5087719298245614, test_dis_acc=0.0\n",
      "\n",
      "Epoch 12\n",
      "loss=0.022415539906968384, kl_loss=0.0003342090435979659, pred_loss=0.005855033170526255, dis_loss=0.01622629795971437, joint_acc=0.8714285714285714, class_acc=0.9171428571428571, dis_acc=0.6062378167641326\n",
      "\n",
      "val_loss=0.08855360878838434, val_kl_loss=0.0005675886240270403, val_pred_loss=0.0255475918451945, val_dis_loss=0.06243842442830404, val_joint_acc=0.0, val_class_acc=0.7111111111111111, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.0780988241496839, test_kl_loss=0.000625220764624445, test_pred_loss=0.026181745947453015, test_dis_loss=0.05129185894079376, test_joint_acc=0.0, test_class_acc=0.5789473684210527, test_dis_acc=0.0\n",
      "\n",
      "Epoch 13\n",
      "loss=0.024290626044394213, kl_loss=0.00027747281244275165, pred_loss=0.006502265019839735, dis_loss=0.017510888375501653, joint_acc=0.8571428571428571, class_acc=0.9, dis_acc=0.6159844054580896\n",
      "\n",
      "val_loss=0.10593795776367188, val_kl_loss=0.00038021562827958, val_pred_loss=0.039247711499532066, val_dis_loss=0.0663100348578559, val_joint_acc=0.0, val_class_acc=0.5333333333333333, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.08626382392749452, test_kl_loss=0.00041132289589497083, test_pred_loss=0.031120126707512036, test_dis_loss=0.05473237288625617, test_joint_acc=0.0, test_class_acc=0.5964912280701754, test_dis_acc=0.0\n",
      "\n",
      "Epoch 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=0.024398054237718934, kl_loss=0.00020799190613856905, pred_loss=0.005284243922310266, dis_loss=0.018905818375230532, joint_acc=0.8828571428571429, class_acc=0.9314285714285714, dis_acc=0.6257309941520468\n",
      "\n",
      "val_loss=0.09120824601915148, val_kl_loss=0.0002967918084727393, val_pred_loss=0.037303956349690755, val_dis_loss=0.05360750092400445, val_joint_acc=0.0, val_class_acc=0.6222222222222222, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.07948094083551775, test_kl_loss=0.0002799253061152341, test_pred_loss=0.03591607746325041, test_dis_loss=0.043284934863709566, test_joint_acc=0.0, test_class_acc=0.5614035087719298, test_dis_acc=0.0\n",
      "\n",
      "Epoch 15\n",
      "loss=0.02136706928295931, kl_loss=8.285282108003227e-05, pred_loss=0.004353846802755639, dis_loss=0.01693036966388918, joint_acc=0.8857142857142857, class_acc=0.9342857142857143, dis_acc=0.6042884990253411\n",
      "\n",
      "val_loss=0.08339019351535373, val_kl_loss=0.00023287754091951582, val_pred_loss=0.03308609591590034, val_dis_loss=0.050071223576863604, val_joint_acc=0.0, val_class_acc=0.6666666666666666, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.07373159810116417, test_kl_loss=0.00032160110902367976, test_pred_loss=0.031892864327681694, test_dis_loss=0.041517132206967004, test_joint_acc=0.0, test_class_acc=0.5964912280701754, test_dis_acc=0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "use_KL=True\n",
    "\n",
    "for p in m.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(f\"Epoch {i+1}\")\n",
    "    \n",
    "    loss, kl_loss, pred_loss, dis_loss, nlab_total = (0,0,0,0,0) \n",
    "    pred_count_joint, pred_count_class, dis_count, lab_total = (0,0,0,0)\n",
    "    \n",
    "    for batch_label, batch_nlabel in itertools.zip_longest(train_label, train_nlabel):\n",
    "        \n",
    "        if batch_label is not None:\n",
    "            labels = batch_label[1]\n",
    "            \n",
    "            if batch_nlabel is not None:\n",
    "                imgs = torch.cat((batch_label[0], batch_nlabel), 0)\n",
    "            else:\n",
    "                imgs = batch_label[0]\n",
    "        else:\n",
    "            imgs = batch_nlabel\n",
    "            labels = None\n",
    "                \n",
    "        batch_results = m.run_batch(imgs, labels, use_KL=use_KL, rep_loss=rep_loss, risk_loss=risk_loss)\n",
    "        loss += batch_results[0]\n",
    "        kl_loss += batch_results[1]\n",
    "        pred_loss += batch_results[2]\n",
    "        dis_loss += batch_results[3]\n",
    "        pred_count_joint += batch_results[4]\n",
    "        pred_count_class += batch_results[5]\n",
    "        dis_count += batch_results[6]\n",
    "        \n",
    "        if batch_label is not None:\n",
    "            lab_total += batch_label[1].shape[0]\n",
    "        if batch_nlabel is not None:\n",
    "            nlab_total += batch_nlabel.shape[0]\n",
    "    total = lab_total + nlab_total\n",
    "        \n",
    "    print(f\"loss={loss/total}, \"\n",
    "          f\"kl_loss={kl_loss/total}, \" \n",
    "          f\"pred_loss={pred_loss/total}, \"\n",
    "          f\"dis_loss={dis_loss/total}, \"\n",
    "          f\"joint_acc={pred_count_joint/lab_total}, \"\n",
    "          f\"class_acc={pred_count_class/lab_total}, \"\n",
    "          f\"dis_acc={dis_count/total}\"\n",
    "         )\n",
    "    print()\n",
    "    \n",
    "    loss, kl_loss, pred_loss, dis_loss, total = (0,0,0,0,0) \n",
    "    pred_count_joint, pred_count_class, dis_count = (0,0,0)\n",
    "    \n",
    "    for data in val:    \n",
    "        imgs, labels = data   \n",
    "        batch_results = m.run_batch(imgs, labels, training=False, use_KL=use_KL, rep_loss=rep_loss, risk_loss=risk_loss)\n",
    "        loss += batch_results[0]\n",
    "        kl_loss += batch_results[1]\n",
    "        pred_loss += batch_results[2]\n",
    "        dis_loss += batch_results[3]\n",
    "        pred_count_joint += batch_results[4]\n",
    "        pred_count_class += batch_results[5]\n",
    "        dis_count += batch_results[6]\n",
    "        total += data[1].shape[0]  \n",
    "            \n",
    "    print(f\"val_loss={loss/total}, \"\n",
    "          f\"val_kl_loss={kl_loss/total}, \" \n",
    "          f\"val_pred_loss={pred_loss/total}, \"\n",
    "          f\"val_dis_loss={dis_loss/total}, \"\n",
    "          f\"val_joint_acc={pred_count_joint/total}, \"\n",
    "          f\"val_class_acc={pred_count_class/total}, \"\n",
    "          f\"val_dis_acc={dis_count/total}\"\n",
    "         )\n",
    "    print()\n",
    "\n",
    "    \n",
    "    loss, kl_loss, pred_loss, dis_loss, total = (0,0,0,0,0) \n",
    "    pred_count_joint, pred_count_class, dis_count = (0,0,0)\n",
    "    for data in test:\n",
    "        imgs, labels = data\n",
    "        batch_results = m.run_batch(imgs, labels, training=False, use_KL=use_KL, rep_loss=rep_loss, risk_loss=risk_loss)\n",
    "        loss += batch_results[0]\n",
    "        kl_loss += batch_results[1]\n",
    "        pred_loss += batch_results[2]\n",
    "        dis_loss += batch_results[3]\n",
    "        pred_count_joint += batch_results[4]\n",
    "        pred_count_class += batch_results[5]\n",
    "        dis_count += batch_results[6]\n",
    "        total += data[1].shape[0]     \n",
    "        \n",
    "    print(f\"test_loss={loss/total}, \"\n",
    "          f\"test_kl_loss={kl_loss/total}, \" \n",
    "          f\"test_pred_loss={pred_loss/total}, \"\n",
    "          f\"test_dis_loss={dis_loss/total}, \"\n",
    "          f\"test_joint_acc={pred_count_joint/total}, \"\n",
    "          f\"test_class_acc={pred_count_class/total}, \"\n",
    "          f\"test_dis_acc={dis_count/total}\"\n",
    "         )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DANN(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        classes=65\n",
    "    ):\n",
    "        super(DANN, self).__init__()\n",
    "        self.classes = classes\n",
    "        self.encoder = build_encoder()\n",
    "        self.classifier = build_classifier(512, self.classes, False)\n",
    "        self.discriminator = build_discriminator(512)\n",
    "    \n",
    "    def forward(self, inputs, rep_loss=1):\n",
    "        features = self.encoder(inputs)\n",
    "        classes = self.classifier(features)\n",
    "        domains = self.discriminator(ReverseLayer.apply(features, rep_loss))\n",
    "        return classes, domains\n",
    "    \n",
    "    def run_batch(self, imgs, labels=None, training=True, rep_loss=1):\n",
    "        if training:\n",
    "            opt = optim.Adam(self.parameters(), lr=1e-4)\n",
    "            opt.zero_grad()\n",
    "            \n",
    "        class_pred_loss = 0\n",
    "        pred_count_class = 0\n",
    "        \n",
    "        imgs = imgs.cuda()\n",
    "        y_pred, domain_pred_label = self(imgs) \n",
    "        \n",
    "        if labels is not None:\n",
    "            labels = labels.cuda()\n",
    "            labels = labels.to(dtype=torch.int64)\n",
    "            class_labels = labels[:,1]\n",
    "            domain_labels = torch.cat((labels[:,0], torch.ones(imgs.shape[0] - labels.shape[0], dtype=torch.long).cuda()), 0)\n",
    "\n",
    "            y_pred = y_pred[:labels.shape[0]]\n",
    "\n",
    "            class_pred_loss = torch.nn.NLLLoss()(torch.log(y_pred), class_labels)\n",
    "            pred_count_class = int(torch.count_nonzero(torch.argmax(y_pred, 1) == class_labels))\n",
    "             \n",
    "        dis_loss = torch.nn.NLLLoss()(torch.log(domain_pred_label), domain_labels) * rep_loss\n",
    "        dis_count = int(torch.count_nonzero(torch.argmax(domain_pred_label, 1) == domain_labels))\n",
    "        \n",
    "        loss = class_pred_loss + dis_loss\n",
    "\n",
    "        if training:\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        return (\n",
    "            float(loss),  \n",
    "            float(class_pred_loss), \n",
    "            float(dis_loss), \n",
    "            float(pred_count_class),\n",
    "            float(dis_count)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rhc37/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    }
   ],
   "source": [
    "dann = DANN(classes=len(d.classes))\n",
    "_ = dann.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "loss=0.029174270220899676, pred_loss=0.028099820627803692, dis_loss=0.00107444961125042, class_acc=0.36826347305389223, dis_acc=0.6510721247563352\n",
      "\n",
      "val_loss=0.05201121436225043, val_pred_loss=0.02787361145019531, val_dis_loss=0.02413760291205512, val_class_acc=0.4222222222222222, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.04142024642542789, test_pred_loss=0.02256692919814796, test_dis_loss=0.018853317227279932, test_class_acc=0.45614035087719296, test_dis_acc=0.0\n",
      "\n",
      "Epoch 2\n",
      "loss=0.03042834834513376, pred_loss=0.02361818038464522, dis_loss=0.006810167938703217, class_acc=0.5029940119760479, dis_acc=0.631578947368421\n",
      "\n",
      "val_loss=0.07134602864583334, val_pred_loss=0.026157898373074, val_dis_loss=0.04518813027275933, val_class_acc=0.4888888888888889, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.05892959812231231, test_pred_loss=0.023572536936977452, test_dis_loss=0.03535706118533486, test_class_acc=0.47368421052631576, test_dis_acc=0.0\n",
      "\n",
      "Epoch 3\n",
      "loss=0.030507138017092997, pred_loss=0.019705610317096375, dis_loss=0.010801528273676803, class_acc=0.5778443113772455, dis_acc=0.6335282651072125\n",
      "\n",
      "val_loss=0.09169868893093533, val_pred_loss=0.02997811900244819, val_dis_loss=0.06172056727939182, val_class_acc=0.4888888888888889, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.07411993595591762, test_pred_loss=0.025813784515648558, test_dis_loss=0.048306155623051156, test_class_acc=0.42105263157894735, test_dis_acc=0.0\n",
      "\n",
      "Epoch 4\n",
      "loss=0.03062821828831009, pred_loss=0.015921106928738004, dis_loss=0.014707111359572086, class_acc=0.6826347305389222, dis_acc=0.6198830409356725\n",
      "\n",
      "val_loss=0.09386359320746528, val_pred_loss=0.024239691098531087, val_dis_loss=0.06962390475802951, val_class_acc=0.5333333333333333, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.07852632957592345, test_pred_loss=0.02432436273809065, test_dis_loss=0.05420197102061489, test_class_acc=0.42105263157894735, test_dis_acc=0.0\n",
      "\n",
      "Epoch 5\n",
      "loss=0.02963799633245487, pred_loss=0.013052544572897125, dis_loss=0.016585451730510646, class_acc=0.7784431137724551, dis_acc=0.6198830409356725\n",
      "\n",
      "val_loss=0.10351280636257595, val_pred_loss=0.03195347256130642, val_dis_loss=0.07155933909946018, val_class_acc=0.4666666666666667, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.08659287502891139, test_pred_loss=0.031081689031500565, test_dis_loss=0.05551119018019291, test_class_acc=0.42105263157894735, test_dis_acc=0.0\n",
      "\n",
      "Epoch 6\n",
      "loss=0.027793641443605775, pred_loss=0.010001606876157646, dis_loss=0.017792034494830387, class_acc=0.8502994011976048, dis_acc=0.6081871345029239\n",
      "\n",
      "val_loss=0.1148018095228407, val_pred_loss=0.03831384711795383, val_dis_loss=0.07648795975579156, val_class_acc=0.4888888888888889, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.09781394088477419, test_pred_loss=0.03825421082346063, test_dis_loss=0.059559730061313564, test_class_acc=0.42105263157894735, test_dis_acc=0.0\n",
      "\n",
      "Epoch 7\n",
      "loss=0.027097977276666355, pred_loss=0.008508295285539088, dis_loss=0.018589681889462424, class_acc=0.8892215568862275, dis_acc=0.6335282651072125\n",
      "\n",
      "val_loss=0.11154002083672418, val_pred_loss=0.03790092998080784, val_dis_loss=0.07363909085591634, val_class_acc=0.4444444444444444, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.08402418671992787, test_pred_loss=0.025881123124507435, test_dis_loss=0.05814306359542044, test_class_acc=0.5789473684210527, test_dis_acc=0.0\n",
      "\n",
      "Epoch 8\n",
      "loss=0.02636782929562686, pred_loss=0.007281815041343139, dis_loss=0.019086014050954034, class_acc=0.9191616766467066, dis_acc=0.6374269005847953\n",
      "\n",
      "val_loss=0.09127944310506185, val_pred_loss=0.033178959952460396, val_dis_loss=0.058100483152601454, val_class_acc=0.6, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.09120459305612665, test_pred_loss=0.04516903977645071, test_dis_loss=0.046035553279675935, test_class_acc=0.3684210526315789, test_dis_acc=0.0\n",
      "\n",
      "Epoch 9\n",
      "loss=0.02384787577169913, pred_loss=0.007265386583744666, dis_loss=0.016582489449378342, class_acc=0.8952095808383234, dis_acc=0.631578947368421\n",
      "\n",
      "val_loss=0.10261319478352865, val_pred_loss=0.037215256690979005, val_dis_loss=0.06539794074164497, val_class_acc=0.5777777777777777, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.09208098629064727, test_pred_loss=0.04173614267717328, test_dis_loss=0.050344843613473994, test_class_acc=0.5087719298245614, test_dis_acc=0.0\n",
      "\n",
      "Epoch 10\n",
      "loss=0.020924443273748802, pred_loss=0.003817861656464099, dis_loss=0.017106581762520192, class_acc=0.9431137724550899, dis_acc=0.6374269005847953\n",
      "\n",
      "val_loss=0.10362114376491971, val_pred_loss=0.03728836907280816, val_dis_loss=0.06633277469211155, val_class_acc=0.6, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.09547330622087445, test_pred_loss=0.044118814301072506, test_dis_loss=0.051354491919801945, test_class_acc=0.543859649122807, test_dis_acc=0.0\n",
      "\n",
      "Epoch 11\n",
      "loss=0.020473568702069407, pred_loss=0.002236634325853333, dis_loss=0.018236934732043023, class_acc=0.9670658682634731, dis_acc=0.5984405458089669\n",
      "\n",
      "val_loss=0.12977623409695097, val_pred_loss=0.06469129986233181, val_dis_loss=0.06508492893642849, val_class_acc=0.4222222222222222, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.09383179848654229, test_pred_loss=0.04390435051499752, test_dis_loss=0.04992744797154477, test_class_acc=0.5087719298245614, test_dis_acc=0.0\n",
      "\n",
      "Epoch 12\n",
      "loss=0.022535823358197427, pred_loss=0.004166746802526376, dis_loss=0.018369076544778387, class_acc=0.9491017964071856, dis_acc=0.6237816764132553\n",
      "\n",
      "val_loss=0.11069405873616536, val_pred_loss=0.043495061662462024, val_dis_loss=0.0671989917755127, val_class_acc=0.5777777777777777, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.09418700034158271, test_pred_loss=0.04308794674120451, test_dis_loss=0.05109905778316029, test_class_acc=0.5614035087719298, test_dis_acc=0.0\n",
      "\n",
      "Epoch 13\n",
      "loss=0.02561873278887416, pred_loss=0.0057416357822556476, dis_loss=0.01987709685956758, class_acc=0.9311377245508982, dis_acc=0.6042884990253411\n",
      "\n",
      "val_loss=0.11016110314263237, val_pred_loss=0.051997301313612194, val_dis_loss=0.05816380182902018, val_class_acc=0.5333333333333333, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.09117242746185839, test_pred_loss=0.046542778349759284, test_dis_loss=0.044629649112099094, test_class_acc=0.5087719298245614, test_dis_acc=0.0\n",
      "\n",
      "Epoch 14\n",
      "loss=0.022688189677560075, pred_loss=0.005413307408942, dis_loss=0.017274882303111503, class_acc=0.9311377245508982, dis_acc=0.6062378167641326\n",
      "\n",
      "val_loss=0.10695059034559462, val_pred_loss=0.043007082409328885, val_dis_loss=0.06394350793626573, val_class_acc=0.6666666666666666, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.0964902074713456, test_pred_loss=0.04642300856740851, test_dis_loss=0.05006719890393709, test_class_acc=0.5614035087719298, test_dis_acc=0.0\n",
      "\n",
      "Epoch 15\n",
      "loss=0.023175807143280148, pred_loss=0.0043213268411554555, dis_loss=0.01885448036021889, class_acc=0.9461077844311377, dis_acc=0.6081871345029239\n",
      "\n",
      "val_loss=0.13141538831922744, val_pred_loss=0.06858803961012098, val_dis_loss=0.0628273540072971, val_class_acc=0.4888888888888889, val_dis_acc=0.0\n",
      "\n",
      "test_loss=0.10411178020008824, test_pred_loss=0.0554303579163133, test_dis_loss=0.04868142228377493, test_class_acc=0.5263157894736842, test_dis_acc=0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rep_loss=1\n",
    "\n",
    "for p in dann.parameters():\n",
    "    p.requires_grad = True    \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    \n",
    "    loss, pred_loss, dis_loss, nlab_total = (0,0,0,0) \n",
    "    pred_count_class, dis_count, lab_total = (0,0,0)\n",
    "    len_dataloader = max(len(train_label), len(train_nlabel))\n",
    "    \n",
    "    for i, (batch_label, batch_nlabel) in enumerate(itertools.zip_longest(train_label, train_nlabel)):\n",
    "        \n",
    "        p = float(i + epoch * len_dataloader) / epochs / len_dataloader\n",
    "        rep_loss=2. / (1. + np.exp(-10 * p)) - 1\n",
    "        \n",
    "        if batch_label is not None:\n",
    "            labels = batch_label[1]\n",
    "            \n",
    "            if batch_nlabel is not None:\n",
    "                imgs = torch.cat((batch_label[0], batch_nlabel), 0)\n",
    "            else:\n",
    "                imgs = batch_label[0]\n",
    "        else:\n",
    "            imgs = batch_nlabel\n",
    "            labels = None\n",
    "                \n",
    "        batch_results = dann.run_batch(imgs, labels, rep_loss=rep_loss)\n",
    "        loss += batch_results[0]\n",
    "        pred_loss += batch_results[1]\n",
    "        dis_loss += batch_results[2]\n",
    "        pred_count_class += batch_results[3]\n",
    "        dis_count += batch_results[4]\n",
    "        \n",
    "        if batch_label is not None:\n",
    "            lab_total += batch_label[1].shape[0]\n",
    "        if batch_nlabel is not None:\n",
    "            nlab_total += batch_nlabel.shape[0]\n",
    "    total = lab_total + nlab_total\n",
    "        \n",
    "    print(f\"loss={loss/total}, \"\n",
    "          f\"pred_loss={pred_loss/total}, \"\n",
    "          f\"dis_loss={dis_loss/total}, \"\n",
    "          f\"class_acc={pred_count_class/lab_total}, \"\n",
    "          f\"dis_acc={dis_count/total}\"\n",
    "         )\n",
    "    print()\n",
    "    \n",
    "    loss, pred_loss, dis_loss, total = (0,0,0,0) \n",
    "    pred_count_class, dis_count = (0,0)\n",
    "    \n",
    "    for data in val:    \n",
    "        imgs, labels = data   \n",
    "        batch_results = dann.run_batch(imgs, labels, training=False, rep_loss=rep_loss)\n",
    "        loss += batch_results[0]\n",
    "        pred_loss += batch_results[1]\n",
    "        dis_loss += batch_results[2]\n",
    "        pred_count_class += batch_results[3]\n",
    "        dis_count += batch_results[4]\n",
    "        total += data[1].shape[0]  \n",
    "            \n",
    "    print(f\"val_loss={loss/total}, \"\n",
    "          f\"val_pred_loss={pred_loss/total}, \"\n",
    "          f\"val_dis_loss={dis_loss/total}, \"\n",
    "          f\"val_class_acc={pred_count_class/total}, \"\n",
    "          f\"val_dis_acc={dis_count/total}\"\n",
    "         )\n",
    "    print()\n",
    "\n",
    "    \n",
    "    loss, pred_loss, dis_loss, total = (0,0,0,0) \n",
    "    pred_count_class, dis_count = (0,0)\n",
    "    for data in test:\n",
    "        imgs, labels = data\n",
    "        batch_results = dann.run_batch(imgs, labels, training=False, rep_loss=rep_loss)\n",
    "        loss += batch_results[0]\n",
    "        pred_loss += batch_results[1]\n",
    "        dis_loss += batch_results[2]\n",
    "        pred_count_class += batch_results[3]\n",
    "        dis_count += batch_results[4]\n",
    "        total += data[1].shape[0]       \n",
    "        \n",
    "    print(f\"test_loss={loss/total}, \"\n",
    "          f\"test_pred_loss={pred_loss/total}, \"\n",
    "          f\"test_dis_loss={dis_loss/total}, \"\n",
    "          f\"test_class_acc={pred_count_class/total}, \"\n",
    "          f\"test_dis_acc={dis_count/total}\"\n",
    "         )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.04912133802447403, test_kl_loss=0.0032100612134264225, test_pred_loss=0.023766850170336272, test_dis_loss=0.022144424287896407, test_joint_acc=0.17543859649122806, test_class_acc=0.24561403508771928, test_dis_acc=0.0\n"
     ]
    }
   ],
   "source": [
    "loss, kl_loss, pred_loss, dis_loss, total = (0,0,0,0,0) \n",
    "pred_count_joint, pred_count_class, dis_count = (0,0,0)\n",
    "for data in test:\n",
    "    batch_results = m.run_batch(data, training=False, use_KL=use_KL, rep_loss=rep_loss)\n",
    "    loss += batch_results[0]\n",
    "    kl_loss += batch_results[1]\n",
    "    pred_loss += batch_results[2]\n",
    "    dis_loss += batch_results[3]\n",
    "    pred_count_joint += batch_results[4]\n",
    "    pred_count_class += batch_results[5]\n",
    "    dis_count += batch_results[6]\n",
    "    total += data[1].shape[0]\n",
    "\n",
    "print(f\"test_loss={loss/total}, \"\n",
    "      f\"test_kl_loss={kl_loss/total}, \" \n",
    "      f\"test_pred_loss={pred_loss/total}, \"\n",
    "      f\"test_dis_loss={dis_loss/total}, \"\n",
    "      f\"test_joint_acc={pred_count_joint/total}, \"\n",
    "      f\"test_class_acc={pred_count_class/total}, \"\n",
    "      f\"test_dis_acc={dis_count/total}\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in test:\n",
    "    imgs, labels = data\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_label, batch_nlabel in itertools.zip_longest(train_label, train_nlabel):\n",
    "    imgs_label , labels = batch_label\n",
    "    imgs_nlabel = batch_nlabel\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2744, 0.2950, 0.2825, 0.3014, 0.2855, 0.2858, 0.2895, 0.2864, 0.2892,\n",
       "        0.2879, 0.2831, 0.2841, 0.2889, 0.2999, 0.2810, 0.2836, 0.2994, 0.2932,\n",
       "        0.2896, 0.2690, 0.2878, 0.2886, 0.2119, 0.2940, 0.2667, 0.2445, 0.2914,\n",
       "        0.2854, 0.2884, 0.2849, 0.2927, 0.2858], device='cuda:0',\n",
       "       grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, domain_pred = m(imgs_nlabel.cuda())\n",
    "domain_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([57])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(torch.sum(y_pred, 1), 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([57])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2., 3., 4., 4., 2., 2., 1., 3., 2., 4., 4., 2., 2., 2., 2., 2.,\n",
       "        1., 3., 2., 1., 3., 4., 1., 3., 4., 1., 4., 3., 2., 1., 3., 4., 4., 4.,\n",
       "        1., 3., 4., 3., 2., 3., 2., 2., 1., 3., 3., 3., 4., 1., 1., 1., 1., 4.,\n",
       "        4., 2., 4.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4386, device='cuda:0')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.count_nonzero(torch.argmax(torch.sum(y_pred, 1), 1) == labels[:,1].cuda()) / labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred[:1]\n",
    "y_joint = torch.reshape(y_pred, (1, 2*4))\n",
    "    \n",
    "y_class = torch.unsqueeze(torch.sum(y_pred, 1), 1)\n",
    "y_domain = torch.unsqueeze(torch.sum(y_pred, 2), -1)\n",
    "    \n",
    "    \n",
    "y_ind_joint = torch.reshape((y_domain * y_class), (1,2*4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2102, 0.3443, 0.0579, 0.0241],\n",
       "         [0.0946, 0.2194, 0.0309, 0.0186]]], device='cuda:0',\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2102, 0.3443, 0.0579, 0.0241, 0.0946, 0.2194, 0.0309, 0.0186]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3048, 0.5637, 0.0888, 0.0427]]], device='cuda:0',\n",
       "       grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6365],\n",
       "         [0.3635]]], device='cuda:0', grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1940, 0.3588, 0.0565, 0.0272, 0.1108, 0.2049, 0.0323, 0.0155]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ind_joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(inf)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.KLDivLoss(log_target=True, reduction=\"sum\")(\n",
    "    torch.log(y_joint), \n",
    "    torch.log(y_ind_joint)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence(p, q):\n",
    "    p = p.reshape(-1)\n",
    "    q = q.reshape(-1)\n",
    "    print(p, q)\n",
    "    return sum(p[i] * torch.log2(p[i]/q[i]) for i in range(len(p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2102, 0.3443, 0.0579, 0.0241, 0.0946, 0.2194, 0.0309, 0.0186],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>) tensor([0.1940, 0.3588, 0.0565, 0.0272, 0.1108, 0.2049, 0.0323, 0.0155],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0046, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_divergence(y_joint, y_ind_joint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
